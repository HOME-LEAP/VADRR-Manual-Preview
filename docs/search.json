[{"path":"index.html","id":"about","chapter":"About","heading":"About","text":"guide extract data systematic reviews VADRR.","code":""},{"path":"start.html","id":"start","chapter":"1 Getting Started","heading":"1 Getting Started","text":"first thing ’ll need get started register VADRR.VADRR currently available general public. like access VADRR, please contact scott.parrott@rutgers.eduThat’s takes! Now ready begin setting project creating data extraction template.","code":""},{"path":"setup.html","id":"setup","chapter":"2 Setting Up Your Project","heading":"2 Setting Up Your Project","text":"three things need set project SRDR.Create project enter basic project informationCreate key questionsEnter project members","code":""},{"path":"setup.html","id":"creating-your-project","chapter":"2 Setting Up Your Project","heading":"2.1 Creating Your Project","text":"registering VADRR account, ’ll sent email confirmation. ’ve confirmed registration logged , ’ll taken Projects page. won’t see projects listed just yet. , ’ll need create first project. , just click Create Project button.Next, ’ll prompted give new project name (want) brief description. , just click Submit button create project.Note pulldown just Submit button populated default “Create empty project.” However, evidence extractions created platforms (e.g., Distiller SR) can archived VADRR. pulldown allows users archive projects.creating new project, need worry using .click Submit button, taken page can add details project.","code":""},{"path":"setup.html","id":"enter-your-key-questions","chapter":"2 Setting Up Your Project","heading":"2.2 Enter Your Key Questions","text":"Next, want set key questions project. Click Key Questions option Project Info tab.take page set Key Questions (e.g., PICO questions) project.entered Key Questions, ’ll option begin building data extraction form. ’ll find button bottom right Key Questions page., begin creating data extraction template, may want add additional members team. can always add team members later, setup, let’s go ahead see add members set project roles.","code":""},{"path":"setup.html","id":"enter-project-members-and-set-their-roles","chapter":"2 Setting Up Your Project","heading":"2.3 Enter Project Members and Set Their Roles","text":"Just Project Information Key Questions, ’ll find Members Roles link top page Project Info tab.open Members & Roles page, see following.walk options now.First, need enter new team member’s ID (email used registered VADRR) project. someone registers VADRR, email becomes ID.Second, ’ll define new team member’s role. role ability different things project.    Leaders: Since set project, default Leader access functionalities within VADRR. can one Leader per project. However, want careful designating leaders. can change anything project (even delete project!), can cause confusion problems. especially true leaders experience systematic review projects VADRR. , judicious designating someone Leader.\n   Consolidators: members whose primary job serve referee duplicate (triplicate, etc.) extractions. instance, articles project double extracted (.e., two people extracting article quality assurance purposes), Consolidator person adjudicate extractions disagreement extractors. Often, want third person involved initial data extractions serve quality check.\n   Contributors: members data extractors project. can also serve screeners project.\n   Auditors: individuals make changes project, can view project (e.g., additional quality assurance step).\n   Experts: screening tool (see VADRR 4.0.1 Screening Tool Resources Team Leaders), ability differentiate topical experts novices. Identifying topical experts can ensure article screened without least one expert viewing article.full description different things different roles can .Finally, ’ve set member’s role, just click Save Changes.Note, ever need add new member project, can always add clicking Project Details tab selecting Members & Roles link. can also add/modify Keywords Project Information time well.","code":""},{"path":"upload.html","id":"upload","chapter":"3 Uploading Article Citations","heading":"3 Uploading Article Citations","text":"can assign screening tasks assign articles extraction, need upload article citations VADRR. page provides instructions .enter citations article Project Info / Citations link.now Citations page. couple ways add citations. can add citations one time bulk list citations reference manager export file.","code":""},{"path":"upload.html","id":"adding-citations-one-at-a-time","chapter":"3 Uploading Article Citations","heading":"3.1 Adding Citations One at a Time","text":"Click Add Citation button.\nclick Create Add Citation link, dialogue box opens.now couple options:\n|\n|First, can manually type citation information fields. recommend use option articles Pubmed ID number.Second, can enter Pubmed ID number top Accession Number field click Fetch Pubmed link.click Fetch link, VADRR populate citation fields automatically.","code":""},{"path":"upload.html","id":"adding-many-citations-from-a-file","chapter":"3 Uploading Article Citations","heading":"3.2 Adding Many Citations from a File","text":"collected citations reference manager file comma delimited spreadsheet file, can upload many citations .important know types files upload (trying upload wrong type file work, may import junk citation list). , sure look types files can upload.types files can upload.Note clicking one file type links listed download template can enter information articles. entered reference information file template, just save drag drop file Drop Files Upload box.Special Note Endnote Export: using Endnote 20 later, may want export selected references text file use RefMan (RIS) Export output style. Use following settings:citation export file created, can simply drag drop box.","code":""},{"path":"upload.html","id":"confirming-correct-citation-format","chapter":"3 Uploading Article Citations","heading":"3.3 Confirming Correct Citation Format","text":"uploaded file, now need confirm file cite structure correct.citations upload immediately. VADRR require confirm detected format file correct. , click Confirm.VADRR one confirmation step: show example uploaded citations. format looks correct, click Start Import button.now receive message file uploaded. upload jobs queued server, large files can take time. receive email confirmation upload completed.small number references, can click refresh button, see newly uploaded citations.upload complete, can navigate back citations page.several options dealing uploaded citations.can reorder citations clicking sort buttons column.can edit delete citations using controls right side page.","code":""},{"path":"upload.html","id":"deduplication","chapter":"3 Uploading Article Citations","heading":"3.4 Deduplication","text":"Even though likely deduplicated citations within reference manager, deduplication often imperfect. , don’t surprised find VADRR detected duplicate references.duplicate references, see option top page deduplicate citations. can click deduplicate.","code":""},{"path":"vadrr-screener.html","id":"vadrr-screener","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4 Screening: Insructions for Screening Set Up (Project Leads)","text":"chapter meant team members setting screening tasks. instructions screeners, see VADRR 5. Screening: Instructions Screeners.many systematic reviews, thorough search result hundreds thousands potential articles. Institutes Medicine guidelines indicate title/abstract screening carried two members review team working independently (see Standards Finding Assessing Individual Studies Standards Finding Assessing Individual Studies – Finding Works Health Care – NCBI Bookshelf.Double-screening thousands titles abstracts can difficult time-consuming.However, VADRR incorporates screening tool uses advanced machine learning (ML) models help team efficiently identify studies appropriate project.ML screener uses inclusion/exclusion decisions team members create prediction (calculate probability) score every article. rearranges articles pull ones likely included front screening queue.ML model relies team member screenings formulate model, n=100 initial screens needed generate model. , won’t see results right away. However, “pearls” (articles already pre-identified inclusion) manually marked inclusion Project Dashboard (see 11.0 Using Project Dashboard), factored ML model default. , beginning project, already set “pearl” articles, want manually mark inclusion Project Dashboard.tutorial, walk different screening setup options, screen, use ML model results make decision regarding stop screening.Yes, ’s right, may need screen thousands articles! meet stopping criteria (), team can stop screening (letting ML model “screen” rest ).part tutorial set two sections:4.1 Resources Team Leaders: section provides information set screening team, set screener meets team’s needs (many options ), track progress.4.2 Resources Screeners: section provides basic instructions members screening team–effectively use tool.","code":""},{"path":"vadrr-screener.html","id":"leaders","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1 Screening Tool Resources for Team Leaders","text":"following, provide step--step instructions project managers set carry title/article screening projects.","code":""},{"path":"vadrr-screener.html","id":"first-step-upload-your-citations-and-then-find-the-abstracttitle-screener","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.1 First Step: Upload Your Citations and Then Find the Abstract/Title Screener","text":"can use Abstract Screening tool, need upload citations (see 3.0 Uploading Article Citations). done , citations automatically entered Abstract Screening Unscreened status Project Dashboard.citations appear , ready set Abstract Screener.get Abstract Screener, simply click Screening link upper navigation bar select Abstract Screening.getting started, need set screening—, determine team screen screen.","code":""},{"path":"vadrr-screener.html","id":"deciding-on-the-screening-team-and-approach","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.2 Deciding on the Screening Team and Approach","text":"working team, screening, need determine:double screening?need pilot screening round?need screeners experts?answers answers “yes”. However, smaller projects (e.g,, class project), criteria may apply.’ll walk .","code":""},{"path":"vadrr-screener.html","id":"double-screening","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.2.1 Double Screening","text":"noted , standard practice double-blind screen citation inclusion/exclusion.means need least two screeners, can certainly work (may help step process move faster). Ideally, least subset screeners deep understanding topical area.","code":""},{"path":"vadrr-screener.html","id":"pilot-screening","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.2.2 Pilot Screening","text":"First, good practice make sure everyone screening team page comes inclusion exclusion. Don’t assume everyone (even experts) completely understand inclusion exclusion criteria. means need :Create detailed instructions including excluding articles: specify criteria related PICO (population? exposures/interventions? comparators? outcomes? language date restrictions? study designs? Etc.)Pilot screen: Rather people simply begin screening, best limited pilot screening. , members screening team screen number articles (usually, 30 articles sufficient).pilot screening, useful meet screeners discuss disagreements reach consensus. able see disagreements using Resolve Conflicts button (see ).","code":""},{"path":"vadrr-screener.html","id":"are-experts-needed","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.2.3 Are Experts Needed?","text":"Ideally, experts topical area serving screeners. However, may also less experienced people team. , may want avoid one article screened two inexperienced individuals. case, need set “Experts” .can Members & Roles page:left team members’ names toggle button. can toggle button indicate experts .Note: smaller project , can single screen automatically expert.several options setting screening team tasks, ’ll walk now.","code":""},{"path":"vadrr-screener.html","id":"setting-up-your-screening-tool","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3 Setting Up Your Screening Tool","text":"Pilot: Use initial training calibration team members. select option, prompted indicate many citations team members assess. N=30 typically sufficient, though may want less depending team.Perpetual Single: citation require one person review, screening continue citations screened. noted , good practice may useful training class projects. Perpetual Double: citation must screened two screeners (combination two screeners ), screening continue citations screened.Perpetual (Expert Needed): citation must screened two screeners, least one must expert. Screening two experts allowed, screening two novices allowed. Screening continue citations screened.Perpetual (Mixed Expert): Two screeners needed citation one must expert, must novice. Two Expert two Novice decisions allowed.Fixed N Size (Single): one screener needed, specified number articles screened (honestly, bit difficult see might apply).Fixed N Size (Double): Double screening (mix Experts Novices), specified number screenings per person. option can useful keep individuals getting overwhelmed (e.g., assigned n=200 cites can “feel” different assigned “many can ”). One downside relies team members actually carry number assigned. screeners volunteers one slow (just things going lives), waiting screen can slow process. Additionally, experience, often people really screening don’t like stop. may consider whether really want put limits folk.Fixed N Size (Expert Needed): least one may two Experts screen article specified N reached.Fixed N Size (Mixed Expert): One Expert One Novice screen citation specified N reached.option choose? noted , small Pilot round ideal. one double screen options meet IOM standards.Deciding perpetual versus fixed: depend team project. found limiting specific number can slow project (limits people want screen , requires screening people busy get screening). highly motivated committed panel screeners, fixed N screening may work fine. Double perpetual generally worked best experience.Experts Novices: mix Experts Novices, likely want choose one options requires least one Expert (allow two Novices screen citation). Using Expert Needed option may allow flexibility cite already one Expert review need “wait” Novice review. members team well trained, one simple double screening options appropriate.Fixed N, many assign? rule , want weigh commitment motivation team. trying keep people feeling overwhelmed, initially assigning n=200 generally good. Note everyone finishes assigned number screenings, need set new screening plan assign next batch. can also achieve much result (without set new screening plan) Double Perpetual simply tell team members screen certain number stop.","code":""},{"path":"vadrr-screener.html","id":"setting-up-rejection-reasons","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.1 Setting Up Rejection Reasons","text":"crucial citation rejection decisions capture reason rejection. table contains settings abstract screening type, see table allows set requirements based user decisions (include reject).","code":""},{"path":"vadrr-screener.html","id":"setting-up-tags","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.2 Setting Up Tags","text":"Tabs multi-purpose labels can used many ways. required use may useful certain circumstances.instance:Identifying background articles. Just citation rejected, may provide useful background information project (e.g., reviews, commentaries, etc.). , may want provide way screeners reject article still mark “background” “interest”.Identifying study purpose: Suppose carrying systematic review multiple questions (e.g., regarding treatment, regarding mechanism, etc.), want presort included articles respective article types. may want require tag included article accepted. instance, following example, tag required decisions (probably needed Yes [include] decisions):extraction screen, tags appear like :, tag use optional, simple projects, may needed.","code":""},{"path":"vadrr-screener.html","id":"using-notes","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.3 Using Notes","text":"Notes also optional can useful “Maybe” decisions. screener indicates maybe, often simply aren’t sure may conflicting reasons include. Getting additional thoughts can help consolidator later make decision regarding inclusion .Setting Notes required Maybe responses may useful.","code":""},{"path":"vadrr-screener.html","id":"screening-form","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.4 Screening Form","text":"VADRR Abstract Screening also option include screening form (basically mini “survey” sorts) can aid screeners making decisions. may especially useful number screening criteria screeners need take account (want ensure give criterion full consideration). screening form can also used confirm right decision made.example, following project, screening form always required, screeners expected complete can render decision. Notice questions dropdown help screeners easily capture information.word caution regarding use screener form: using screener form can ensure thorough screen title/abstract, forcing screeners answer questions can slow screening process. , recommend use screening form, minimize number questions overly burden screeners.One possible benefit using screener form data Abstract Screener captured excel available download (see ). carrying scoping review, screener questions can used data analysis.","code":""},{"path":"vadrr-screener.html","id":"screening-form-builder","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.4.1 Screening Form Builder","text":"Let’s say decide create screening form. ?First, navigate Screening Form option Edit Forms pulldown upper navigation bar.open blank form builder. Click Add Question get started.can begin build questions. Note option select multiple response styles (e.g., radio button, checkbox, etc.).different question structure options may useful :Text: free text entry. recommend using seriously slow screening process.Numeric: number can entered. Unlikely useful screening.Checkbox: Select multiple options. can useful short list inclusion criteria, want screeners include criterion met. use option, may able get single screening form question.Dropdown: Select one option use pulldown menu select. Except yes/questions, less useful radio option.Radio: Select one option presents options user can see .Select One: Select one option provides ability user enter another write another option. unlikely generally useful screening, useful screening scoping review.Select Multiple: Select number pre-specified options additional ability write . unlikely generally useful screening. However, useful screeners confirm set outcomes reported want allow add additional outcomes., caution using screener form without thoughtful planning can slow screening process. use , keep simple (e.g., one checkbox question list inclusion criteria).","code":""},{"path":"vadrr-screener.html","id":"additional-options","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.5 Additional Options","text":"final set options following:Exclusive Users: limit screening tasks specified members team. large team (worried someone designated screener might hop tool begin screening), may want use option. click pulldown opens allows select team members designated screeners. Just select team members.Hide Author Information: projects, may want blind screeners citation authors. may case knowing author’s identity bias screeners either include exclude.Hide Journal Information: may want blind screeners journal article published believe knowing journal bias screeners include exclude.","code":""},{"path":"vadrr-screener.html","id":"finalizing-and-editing-your-screening-settings","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.6 Finalizing and Editing Your Screening Settings","text":"","code":""},{"path":"vadrr-screener.html","id":"configuring-reasons-and-tags","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.7 Configuring Reasons and Tags","text":"can use default settings change toggling button left setting.Allow users add reasons screening. Screeners allowed add additional reasons see fit. reasons appear screening tool team members’ tools. , want limit reasons exclusion (maintain consistency screeners) want toggle option .Allow users add tags screening. Similarly, allow users add tags. user-defined Reasons, screener defined new tag see option screening tool. may useful want allow screeners provide information title/abstract. However, given screeners can use Notes section, may want toggle one , leave , advise screeners use sparingly.Limit users one reason. Screeners need one reason exclude (e.g., wrong population). , often many reasons article may appropriate (wrong population, wrong intervention, wrong outcome, etc.). stage (abstract screening) less important screeners indicate reasons exclusion long identify one valid reason exclusion. can direct screeners just select one reason. However, want allow screeners select multiple reasons, toggle option .","code":""},{"path":"vadrr-screener.html","id":"setting-up-reasons","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.7.1 Setting Up Reasons","text":"can add reasons exclusion, recommend reasons correspond aspects PICO question(s) study design. VADRR comes set pre-specified reasons exclusion based PICO components recommend using (least start ). can add default Reasons clicking Add Default Reasons button. , standard set exclusion Reasons appear:can modify standard reasons following ways:Change position Reasons changing numbering Position column.Edit text Reason clicking edit button Edit columnDelete Reason clicking red trashcan icon Delete columnAdd additional reasons clicking small plus sign button bottom right corner list.might want alter reasons? Every project unique, may unusual reasons exclusion (e.g., animal study) additional reasons (Wrong Language). , recommend starting default reasons editing fit project.","code":""},{"path":"vadrr-screener.html","id":"adding-tags","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.7.2 Adding Tags","text":"choose use tags project, ’ll need enter manually—default set tags. Simply click plus sign button right tags space create tags.click plus sign button, new popup open. Simply enter text new tag click Create Tag button.noted Tags needed projects (especially simple projects), including Background Article option Tag generally good idea. allow screeners alert articles may useful providing background information related research.","code":""},{"path":"vadrr-screener.html","id":"terms-and-phrases-how-to-use-them-with-a-team","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.4 Terms and Phrases: How to Use Them with a Team","text":"VADRR Abstract Screener allows terms highlighted different colors indicate likely acceptance rejection. instance, following example, terms “asthma”, “COPD” “probiotics” strong indicators likely acceptance (highlighted green). terms “microbiome” “inflammatory cytokines” weak indicators acceptance.can also use different highlights indicate weak strong “likely reject.”Using colors terms phrases helps speed screening. instance, even screener reads entire abstract, abstract many terms flagged acceptance give strong initial indication article likely accepted. Similarly, highlighted colors rejection can help quickly flag article unlikely included.","code":""},{"path":"vadrr-screener.html","id":"setting-up-terms-and-phrases-for-groups-for-the-project","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.4.1 Setting Up Terms and Phrases for Groups for the Project","text":"individual screeners can highlight terms, best list terms phrases shared across screeners. promotes consistency!begin screening, meeting screening team discuss inclusion exclusion criteria, good idea brainstorm team terms believe likely indicate inclusion exclusion. instance, limiting studies adults, terms like “child,” “children,” “infants,” etc. may terms want highlight likely exclusion.first open screening window, can scroll right panel Terms Phrases section. see following:point, options:\n* Add Default Groups clicking Add Default Groups button. create list four groups (Group 1, Group 2, etc.) colors pre-assigned. can change group names double clicking group name, changing label, clicking check mark accept changes.can change color clicking color bar. may important members team red/green color blind.can click Edit Terms manually add list terms indicative strongly weakly accept reject. team identified terms categories, want set ahead time. , can use Download Groups button create JSON file contains information. Send file screeners instructions use Import Groups button pull highlighting codes. promote team consistency.Finally, can completely delete group clicking trashcan right group.Manually create groups. decide alter default groups, can create using Add new group field just Download Groups button., simply enter new group name hit return. new group now show list default color. Change color desired.Create Groups assign terms colors directly JSON file. familiar JSON files, can use JSON editor create code uploading JSON file. example JSON file syntax define groups, assign colors, indicate terms associated group. can also download JSON file edit manually, re-upload .","code":""},{"path":"vadrr-screener.html","id":"resolving-conflicts","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.5 Resolving Conflicts","text":"screening proceeded, inevitably screeners disagree whether include exclude article. Additionally, article marked “maybe” marked “conflict”. need resolve conflicts.can find Resolve Conflicts button main Abstract Screening page.Clicking button open Screener page. point, couple options:Resolve conflict referring screener decisions rationales. abstract, now see labels assigned screeners, along whatever reasons notes screeners entered. can read abstract decide screener decisions (make entirely different decision ). Use green red decision button make final inclusion judgment. Resolve conflict referring screener decisions rationales. abstract, now see labels assigned screeners, along whatever reasons notes screeners entered. can read abstract decide screener decisions (make entirely different decision ). Use green red decision button make final inclusion judgment. Resolve conflict blinded. want make truly blind decision, can click purple Labels button eye just screener decisions. make screener decisions disappear can make assessment . Note decision overrides screener decisions.Resolve conflict blinded. want make truly blind decision, can click purple Labels button eye just screener decisions. make screener decisions disappear can make assessment . Note decision overrides screener decisions.","code":""},{"path":"vadrr-screener.html","id":"understanding-and-using-the-machine-learning-results","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.6 Understanding and Using the Machine Learning Results","text":"VADRR incorporates powerful Machine Learning (ML) tool (previously Abstrakr) facilitate screening tasks. work?Pearls (articles pre-identified meet inclusion criteria) marked inclusion manually via Project Dashboard. provides first bit information ML model.Screeners initially screen 100 titles abstracts. (second bit information ML needs). first round, articles presented screeners random order.ML creates predictive model (overnight) rearranges articles articles highest probability screened moved front screener queue.Depending complexity project, ML able get pretty reliable model inclusion/exclusion criteria within couple training rounds.Screening continues stopping criteria reached (assumption ML “screened” rest articles.Note: system set err side sensitivity. instance, ML model predicts article 4% chance inclusion, number multiplied 10 appears article 40% probability included. design system runs low chance missing key articles.","code":""},{"path":"vadrr-screener.html","id":"when-do-you-see-results","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.6.1 When Do You See Results?","text":"system set run ML model 100 completed screenings automatically. means need 100 double-screened articles agreement screeners. Note, Maybe responses count.way force ML run fewer screeners (though typically recommend since without sufficient number accurately identified accept/reject decisions, model unlikely able produce reliable model.force ML run fewer 100 new screens, toggle Force Training button main Abstract Screening screen.","code":""},{"path":"vadrr-screener.html","id":"what-do-the-results-mean","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.6.2 What Do the Results Mean?","text":"ML engine runs behind scenes, need worry . can get results model, can useful understanding much screening left .main Abstract Screening page, just Force Training button, Machine Learning Results. Clicking button take page can see ML results. lot resources page, break .Total Number Citations: many citations team successfully screened.Latest Model Time: last time date ML model generatedRejection Streak Counter: number articles rejected two screeners.Estimated Coverage: graphical presentation many studies screened (x-axis) many articles left estimated included. gives rough sense many articles team left screen.Percentage unscreened: proportion articles left screened (example, 46.3% articles unscreened).Untrained citations: number articles double-screened, machine yet processed . ML generate new model counter gets 100.Highest Score: probability highest-scoring article. Higher probabilities indicate likely inclusion. example, highest-scoring article 99.88% probability included.Score Distribution: histogram shows many articles fall different deciles probability distribution. case, see nearly 500 articles 0% 10% probability included (thus, screeners likely never see articles). see much smaller numbers articles 80%-90% range 90-100% range.Enter threshold: want see many articles certain probability included, can change value. default 50%. let’s say set stopping rule articles 40%. can change value .4 get sense many articles left screen. example, can see n=146 articles greater 50% chance inclusion.Next, see table Top 20 Unscreened Citations. valuable table shows reference information articles highest probability included. useful confirming articles left screen likely included. hit stopping criteria (see ), can check titles table confirm none likely included.Note rather wait article double-screened, can click Label link right citation manually accept reject. important remember can break protocol (since article double-screened). , judicious changing label article table.bottom Machine Learning Results page blue button looks like :button allows open series model diagnostic measures. Clicking button show following:right, see confusion matrix shows well model performing. instance, left half matrix shows status articles ML predicted included. n=175 articles ML predicted accepted, n=62 accepted n=113 . Remember, ML set sensitive, likely predict article accepted even isn’t want miss potential articles. Notice 58 articles ML predicted rejected, n=2 rejected. , want number low possible.table right provides formal metrics model’s performance.Precision: measure often model correctly predicts including article (typically fairly low given system set sensitive)Sensitivity: True Positive rate (also called “recall”), tells proportion actually included articles correctly identified included model. want number high (example, 97%).F1 Score: harmonic mean precision sensitivity. overall measure model’s accuracy. , VADRR set overly sensitive, shouldn’t anticipate high value score.Accuracy: measure overall correctness model. proportion correctly predicted articles total number articles.probably sense , way model set (.e., sensitive), numbers going particularly useful. measures, want check Sensitivity. give sense likelihood potentially useful article missed.","code":""},{"path":"vadrr-screener.html","id":"when-should-we-stop-screening","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.6.3 When Should We Stop Screening?","text":"area debate evidence synthesis community. really need screen citations (let’s say thousands) ML working ? , remaining citations low probability inclusion, really make sense continue screening ?recently, researchers developing stopping rules (.e., humans stop screening, rest citations assumed screened ML model). standard screening stop. common approaches include:ML trained, 100 articles row rejected, stop screening.none remaining articles greater 40% chance inclusion (really means 4% chance inclusion).criteria combined.Whichever choose (can choose different stopping rules mentioned ), sure document plan protocol report.","code":""},{"path":"vadrr-screener.html","id":"downloading-screening-results","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.7 Downloading Screening Results","text":"Results screening tasks (Abstract Full-text screening), can downloaded. See VADRR 7. Getting Results VADRR","code":""},{"path":"screener-instruc.html","id":"screener-instruc","chapter":"5 Screening: Instructions for Screeners","heading":"5 Screening: Instructions for Screeners","text":"page meant provide instructions project members using VADRR Abstract Screener tool (previously Abstrakr).","code":""},{"path":"screener-instruc.html","id":"the-basics","chapter":"5 Screening: Instructions for Screeners","heading":"5.1 The Basics","text":"","code":""},{"path":"screener-instruc.html","id":"getting-started","chapter":"5 Screening: Instructions for Screeners","heading":"5.1.1 Getting Started","text":"get abstract screening tool Projects page (landing page VADRR log ), simply click Screening pulldown project working :click Abstract Screening tool, see one “screening tasks”. instance, image can see three different tasks:pilot screening task (small set citations team used calibrate screening decisions,pilot screening task (small set citations team used calibrate screening decisions,n-size-single screening task (one screener set screen n=100 citations),n-size-single screening task (one screener set screen n=100 citations),double-perpetual screening task (citation screened two people, limit number citations).double-perpetual screening task (citation screened two people, limit number citations).Note: screener, see one type screening task sure use, contact project lead confirm working .Simply click Continue Screening button begin (continue) screening.","code":""},{"path":"screener-instruc.html","id":"the-screening-page","chapter":"5 Screening: Instructions for Screeners","heading":"5.2 The Screening Page","text":"use window cycle title/abstracts citations assigned .Note: need change windows different citations. click decision buttons (green check, red X purple ?), system automatically move next citation queue!walk part screen.","code":""},{"path":"screener-instruc.html","id":"title-abstract-and-publication-information","chapter":"5 Screening: Instructions for Screeners","heading":"5.2.1 Title, Abstract and Publication Information","text":"left side screen, see title, abstract publication information (project leader author journal hidden). review information make determination regarding inclusion exclusion (maybe decide).","code":""},{"path":"screener-instruc.html","id":"include-exclude-maybe-choices","chapter":"5 Screening: Instructions for Screeners","heading":"5.2.2 Include / Exclude / Maybe Choices","text":"bottom right screen three buttons:Green check mark: click button mark article included project. article must meet inclusion criteria included.Purple question mark: click button unsure whether article meets inclusion criteria.Red X mark: click button believe article meet inclusion criteria rejected.Tips using Maybe: may tempting use Maybe button often simply sure, given information title abstract, whether article screened . However, caution using Maybe recommend using infrequently possible. several reasons .Using Maybe automatically sets article “conflict” status. Conflict status two screeners disagree (, case, single screener make decision). , means decision still made, consolidator. best , screener, make decision provide much rationale necessary decision hesitations (e.g., Notes).Err side inclusion. title/abstract screening just first screening step—followed full-text screening step—even article ultimately rejected, best let rejected information available (full-text screen).recommend using Maybe genuine question inclusion/exclusion criteria. confusion brought project leader clarification.","code":""},{"path":"screener-instruc.html","id":"rejection-reasons","chapter":"5 Screening: Instructions for Screeners","heading":"5.3 Rejection Reasons","text":"citation can marked rejection, Rejection Reason must provided. project lead set list reasons select . Check project lead questions reasons mean. project lead may allow add additional reasons (check project lead). , can add additional reasons clicking plus sign bottom right Rejection Reasons list.Note: reasons project may differ provided example . Also, project lead may allow select one reason reject article (check project lead). allowed choose one reason (e.g., wrong population, wrong intervention, wrong outcome, etc.), select one .","code":""},{"path":"screener-instruc.html","id":"using-tags","chapter":"5 Screening: Instructions for Screeners","heading":"5.4 Using Tags","text":"projects use tags. list often always used allow provide bit information article. Often, see option “Background article.” Sometimes, may run across article meet inclusion criteria (e.g., review article commentary) think may nonetheless useful project. Selecting Background article tag (available) allow flag article pulled project.","code":""},{"path":"screener-instruc.html","id":"using-notes-1","chapter":"5 Screening: Instructions for Screeners","heading":"5.5 Using Notes","text":"Notes free text field can use reason. Typical reasons using Notes:think article included excluded, may lingering doubt. can use notes field jot thoughts. used case conflict whether include exclude article.gave maybe response. Depending project may required enter rationale Notes field select Maybe option (purple button bottom). enter information weren’t sure one way another—perhaps little information provided abstract.Notes can used reason . may want simply put rationale making decision made. typically necessary (except Maybe projects) option.","code":""},{"path":"screener-instruc.html","id":"screening-form-1","chapter":"5 Screening: Instructions for Screeners","heading":"5.6 Screening Form","text":"projects may use short screening form help assessment. Since may sometimes difficult remember inclusion criteria (many project), project lead may provide question series questions regarding whether inclusion criteria met. simply way help screening.example checklist inclusion criteria must met article included. Note completed screening form question, must mark screening form complete register response.questions regarding screening form, consult project lead directions.","code":""},{"path":"screener-instruc.html","id":"highlighting-terms-for-inclusion-and-exclusion","chapter":"5 Screening: Instructions for Screeners","heading":"5.7 Highlighting Terms for Inclusion and Exclusion","text":"additional feature screening tool terms phrases indicating likely inclusion exclusion can highlighted aid screening process. Highlighting certain terms can speed screening. following example, term “cognitive bias” strongly indicates likely acceptance, “inference” weakly indicates acceptance. contrast, terms “drug” “drugs” strongly indicate rejection.first open abstract much highlighted colors indicating “likely accept”, ’ll know (even reading full abstract) article may good candidate inclusion. Alternatively, many terms indicate “likely reject” can suspect article likely rejected upon full reading.two ways Terms Phrases can highlighted:Project-wide terms phrases: terms phrases decided upon team indicate likely inclusion exclusion. project lead generally create list (working members team) share file (json file). directed import file screening project. , terms take appropriate highlight. import file provided project lead, use Import Groups (JSON format) button Terms Phrases box.Just follow instructions import project list terms phrases.Individualized terms phrases: can also highlight terms . couple ways , easiest simply highlight term phrase within abstract title assign value. highlight word set words, popup open. Simply select appropriate valence highlighted text.Note can also download Terms Phrases Groups defined (e.g., share rest team).Good Practice Note: make sure everyone page screening, good idea entire team working list terms phrases. Work project lead team members identify terms work share across screeners. ","code":""},{"path":"screener-instruc.html","id":"reviewing-and-re-screening","chapter":"5 Screening: Instructions for Screeners","heading":"5.8 Reviewing and Re-screening","text":"notice three buttons center screen just left abstract text.buttons allow following:Labels: want review screenings already completed want return previously screened abstract rescreen (perhaps changed mind), can click button. , popout open left list articles ’ve already screened. clicking title article, can rescreen .Continue Screening: used “Labels” button jump another screened citation, can use Continue Screening button jump back last abstract queue.Exit: want end screening session closeout. Simply click button.","code":""},{"path":"template.html","id":"template","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6 Tips for Creating a Data Extraction Template","text":"talk build different sections let’s talk first general good practices building extraction template.","code":""},{"path":"template.html","id":"structure-your-template-based-on-your-analytic-framework","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.0.1 Structure Your Template Based on Your Analytic Framework","text":"First, types information (data) ’ll want pull research articles guided PICO question analytic framework. Take look back PICO analytic framework think carefully pieces information ’ll need answer question. instance, looking example analytic framework, can already see number fields need add extraction template:\nadditional ideas field extract project, see Chapter 5 Cochrane Handbook.","code":""},{"path":"template.html","id":"organize-questions-within-tabs","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.0.2 Organize Questions within Tabs","text":"Second, know organize questions within template. Happily, VADRR makes easier organizing different types information ’ll need series tabs. example structured data entry form Design Details tab.\n","code":""},{"path":"template.html","id":"goldilocks-principle-for-data-collection","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.0.3 Goldilocks Principle for Data Collection","text":"Third, remember balance little information much information. principle data extraction systematic scoping reviews extracting information need format can use. don’t want extract everything (otherwise, just work full text articles), want enough information allow planned analyses.little information extracted mean either limited analysis may mean going back later update template capture information missed.much information, find yoursel wasting time extracting information need analysis.instance, important plan ahead time sub-analyses carrying meta-analysis. , ’ll need extract information differences samples, interventions, measurement methods, etc. used different research articles. Taking study characteristics account can provide strong evidence interventions exposures tests work differently (.e., different outcomes) different situations. plan ahead capturing information (without trying extract every piece information study).","code":""},{"path":"template.html","id":"use-dependencies-to-help-your-extractors","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.0.4 Use Dependencies to Help Your Extractors","text":"Fourth, can use Dependencies functionality help guide data extractors () knowing questions answer, can safely ignore.set appropriate dependencies, click Save Exit button top right dependency tool screen.","code":""},{"path":"template.html","id":"getting-started-with-the-extraction-template-builder","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.0.5 Getting Started with the Extraction Template Builder","text":"\nList Available Tabs: left see list default tabs defined VADRR.\n\nAdd Section Button: list button: Add Section. projects require additional tabs, flexibility add additional tabs.\n\nSave Instructions: general instructions extractors particular tab, can enter instructions text box.\n\nTab Dependencies: two key tabs structure tabs: Arms Outcomes. make Arm Details dependent Arms, question Arm Details repeat arm defined Arms tab. Similarly, Outcome Details tab dependent Outcomes tab, question Outcome Details tab repeat every outcome defined Outcomes tab. Finally, going carry risk bias outcome (rather article whole), want make Risk Bias tab dependent Outcomes.\n\nPreview Section: can use button top preview look questions.\n\nAdd Question: button allows add new question.\n","code":""},{"path":"template.html","id":"whats-next","chapter":"6 Tips for Creating a Data Extraction Template","heading":"What’s Next?","text":"next series pages show actually set different types questions VADRR.","code":""},{"path":"template.html","id":"struc-ques","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.1 General Principles for Structuring Questions","text":"cover several topics structuring creating questions.","code":""},{"path":"template.html","id":"how-to-structure-questions","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.1.1 How to Structure Questions","text":"decided information need extract, need think best way organize format question capture information optimal format analysis. First, general principle:\ngeneral, possible, best use structured rather free text questions.\n\nText Field: option useful free text entry type information article highly variable unstructured. instance, may want pull narrative article blinding carried (since many ways blind study). , instance, simple text box used capture information presented following example.\n\nHowever, let’s say planned sub-analysis determine whether type blinding effect outcomes. case, may want information text format, want create structured question allow us add type blinding subgroup meta-analysis. case, use following (used Checkbox structure text option “”):\n\nNumeric Field: free-text entry field can used enter numerical values (alphanumeric entry allowed).\n\nCheckbox (select multiple): option good multiple characteristics may present study (different types blinding example).\n\nDropdown: option similar Radio Button option () useful one alternative possible list options fairly restricted (e.g., Yes/). look like data entry screen.\n\nRadio button (select one): Like Dropdown, option useful one alternative possible, unlike Dropdown useful several possible options (awkward Dropdown). radio button option look like .\n\nSelect One (write-option):Select One (write-option)**: want offer extractors use Dropdown flexibility also typing another option, can use question format. However, want use format write-information anything couple words. want space allow extractors enter detail different option necessary. Use radio button question “” option place free-text question second column (’ll show set one column row question later).\n, now second column provides structure options first column. can leave free text adjust default number characters allowed.\nSelect Multiple (write-option): question format allows data extractor select one option (like Checkbox type question) well write option listed. Select One (write-option), use format want allow exactors enter text detailed word two.\n","code":""},{"path":"template.html","id":"setting-up-the-questions","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.1.2 Setting Up the Questions","text":"Now sense different types questions available, actually set question? use example setting radio button question.First, click Add Question button. new empty question appear bottom builder screen.Second, add question text (e.g., Select appropriate study design).Third, add instructions help extractors.Fourth, select appropriate question structure. select Radio. (Note, select question structure question automatically save page refresh. Scroll bottom find question .)Fifth, enter first option center field:Sixth, enter additional options lower entry field. Write option hit Enter save new option (, question save, page refresh). Continue entering answer options question complete. point, can reorder, edit delete options entered.","code":""},{"path":"template.html","id":"using-multiple-rows","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.1.3 Using Multiple Rows","text":"benefit complicated question structure? Rather create whole series separate questions (make page quite long), can use complex question structures gather required information less space.","code":""},{"path":"template.html","id":"reordering-duplicating-and-removing-questions","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.1.4 Reordering, Duplicating and Removing Questions","text":"\ncan reorder questions point.\n\ncan duplicate questions.\n\ncan delete question\n","code":""},{"path":"template.html","id":"question-structure-faqs","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.1.5 Question Structure FAQs","text":"\nable create good Radio Button Checkbox options assumes already knowledge common appropriate options begin structure question. means full-text review stage article selection, looking common patterns options across articles. , instance, answering diagnostic accuracy question three () common types test device manufacturers, take note create structured question allows extractor choose among . Allowing free-text entry situation mean go back analysis phase reclassify device manufacturer entries discrete categories. Save time end structuring questions front possible.\n\nVADRR allows great flexibility structuring questions appear. Sometimes, may want whole series separate questions, multiple sub-questions “fit” within single question. instance, following question seeks collect detail different aspects intervention, requires additional detail intervention component used.\nmultiple row multiple column format used structure question.just created question went preview , don’t see new question. wrong?\nquestions automatically “inherit” key questions defined beginning project. add key questions later, select key questions question apply. example , question sleep apnea added later project. questions automatically appear key question article addresses sleep apnea.implication selecting Key Questions question applies can customize extraction template, making questions appear key questions questions appear key questions.Bottom line: data entry questions linked Key Questions, Key Question selected data entry question, see data entry question show data entry screen.","code":""},{"path":"template.html","id":"piloting-your-questions-for-extractions","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.1.6 Piloting Your Questions for Extractions","text":"Finally, important thing keep mind almost certainly create perfect data extraction template first try. Sometimes ’ll realize questions (options within questions) included didn’t. Sometimes ’ll find data extractors find structure question confusing., data extraction templates pilot tested different team members. can assigning couple articles extraction obtaining feedback team members. extracting alone, plan extract data two three research studies (making alterations extraction template), final extraction form.","code":""},{"path":"template.html","id":"arm-suggest","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.2 Setting up Arm or Diagnostic Test Suggestions","text":"two tabs within VADRR special ways setting questions: Arms (Diagnostic Tests) Outcomes (Diagnoses). tabs different names depending whether carrying diagnostic accuracy project (case talking Diagnostic Tests Diagnoses) type project (case talking Arms Outcomes)., ’ll show set arms provide tips useful ways .","code":""},{"path":"template.html","id":"difference-between-arms-and-diagnostic-tests","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.2.1 Difference Between Arms and Diagnostic Tests","text":"First, Arm setup page projects answering Diagnostic Accuracy questions.\npage projects set answer Diagnostic Accuracy questions. ’ll notice couple tabs different.’ll notice Arms (Diagnostic Tests) setting template providing extractor suggestions. Think building menu extractors can quickly easily draw specifying arms research study.field need enter Name field (best enter description descriptions best left extractor peculiarities particular article).","code":""},{"path":"template.html","id":"how-to-name-arms","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.2.2 How to Name Arms","text":"One thing realize front authors different articles may name essentially arms differently. instance, let’s say PICO question : Among people mental illness, effectiveness multi-component weight loss program compared usual care managing weight status? two studies name essentially arms different ways:Smith 2018: Treatment arm name, “Lifestyle Intervention”; Comparison arm name, “Usual care”Jones 2019: Treatment arm name, “Active Life Intervention”; Comparison arm name, “Standard care”obvious problem extractors name arms exactly authors , go carry analysis sort different names figure intervention interest (“” PICO) comparator arms (“C” PICO). extractors provided structure training front, can mean huge amount work cleaning arm names analysis phase project.interested specific commonly labeled surgery, treatment, drug, etc., , comparator condition always placebo, can provide suggest descriptive “innovative treatment” “comparison treatment”. case, setting arms simple.Now, word caution: using multiple generic labels innovative () “improvement” practice intervention, double extracting data articles (.e., two data extractors working separately article), can cause confusion Consolidation phase project (, third person reconciles differences extractors). Extractor 1 might label arm “Innovative Practice 1” extractor labels arm “Improvement Practice 2”. case, recommend extractors use short description differentiate two innovation arms (, less frequently, two comparison arms).may also want extractors communicate ahead time arm labeled Practice 1 Practice 2. feasible, may want come descriptive (rather generic) label multi-arm studies. , training extractors ahead time key!may wondering capture detail arms assign generic labels. ’ll cover next section.","code":""},{"path":"template.html","id":"when-things-get-much-more-complicated-clinical-practice-guidelines","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.2.3 When Things Get Much More Complicated: Clinical Practice Guidelines","text":"single question systematic reviews, approach generally fine. , projects encompass many questions (like creating Clinical Practice Guidelines)? case, may need several arm suggestions. Always try plan make easier data extractors (less frustration, less time, fewer mistakes). example:just every question clinical practice guideline separate project within VADRR? certainly option may best projects. However, article may apply several clinical practice questions, may efficient keep within project avoid unnecessary duplicate (triplicate!) extractions.Remember, can use multiple key questions can assign different questions (data entry fields) key questions. takes little planning organization may actually help end.","code":""},{"path":"template.html","id":"how-to-set-up-and-name-diagnostic-tests","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.2.4 How to Set Up and Name Diagnostic Tests","text":"Diagnostic Accuracy systematic review, little prep work need can set Diagnostic Tests (Diagnoses).first tell VADRR Results going proper format (different types systematic reviews). , go Results tab first time, see following:naming Diagnostic Tests, basic principles apply mentioned naming Arms: keep simple.instance, familiar polymerase chain reaction (PCR) tests, know different types. Rather extractors enter lots detail tests (, heaven forbid, give essentially test different names) Diagnostic Tests page, keep test suggestions simple (e.g., tests common type, like PCR blood culture) capture detail tests Diagnostic Test Details page.","code":""},{"path":"template.html","id":"arms-details","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.3 The Importance of Arms or Diagnostic Test Details","text":"Treatments, interventions tests rarely exactly studies. example:\nDrug studies: dosage, timing, length treatment may vary somewhat studies.\n\nInterventions: general surgery may differ somewhat technique studies. interventions may include multiple components may combine components different ways across different studies.\n\nDiagnostic accuracy studies: test manufacturers, analytic pre-analytic procedures may vary studies.\nthinking ahead talking using generic suggestions arms, may wondered, “can capture details differences arms?”Arm (Diagnostic Test) Detail tab comes . Capturing details differences arms going vital analysis phase capturing information may explain substantial amount heterogeneity meta-analysis. Essentially, want use Arm Details tab merely capture details different arms, want capture differences among studies treatments, interventions, tests exposures carried measured.differences can used later define subgroup analyses (serve covariates meta-regression) meta-analyses later project!protocol (assuming protocol), likely defined number characteristics might serve effect modifiers. capture detail characteristics Arms Details Test Details tab.bears repeating: capturing detail may prove huge benefit analysis phase.","code":""},{"path":"template.html","id":"what-details-should-you-capture-in-the-arms-or-diagnostic-test-details-tab","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.3.1 What Details Should You Capture in the Arms or Diagnostic Test Details Tab?","text":"depends heavily purpose questions (, noted , defined protocol). also assumes understanding differences might actually make difference results different studies., offer suggestions types Arm Detail questions based different types systematic review questions.Dosage (much? long? often?)TechniqueProvider (e.g., physician, physical therapist, nurse, dietitian, etc.)Mode treatment (e.g., counseling: face face? person?)Intervention format (e.g., individual sessions, group sessions, mixed?)multi-component interventions, different components (e.g., drug, dietary, physical activity, counseling, etc.)?Techniques providing intervention (e.g., physical activity: walking versus aerobic exercise versus strength training, etc.)intervention chains (.e., sequenced practices), components intervention chain included (e.g., pre-analytic procedures –> organism identification –> organism susceptibility –> stewardship communication treating clinician –> treatment technique)?Dosage (much? long? often?)Provider (e.g., physician, physical therapist, nurse, dietitian, etc.)Mode treatment (e.g., counseling: face face? person?)Intervention format (e.g., individual sessions, group sessions, mixed?)Test manufacturerPre-analytic procedures (e.g., diagnosis C diff, requirement unformed stools prior test request?)Differences analytic techniqueDifferent methods measuring exposure (e.g., different methods assessing dietary intake methods airborne hazard measurement)potential confounding variables (.e., sources exposure factors mitigate modify result)list exhaustive, need every one suggested questions asked different types projects. key, however, plan ahead begin building data extraction template details likely important (say, may perhaps affect differences results subjects studies).couple suggestions:\nworking part team knowledge topical area: plan team discussion identify Arm Details questions extracted.\n\nworking alone deep understanding topical area: full-text review phase study selection, keep notes differences see among studies characteristics listed . Reading re-reading articles may help find patterns ’ll want capture data extraction phase.\nOne last thing: suggestions mentioned earlier resource creating structured (versus free text) questions particularly important Arms Details. Using structured questions Arm Details allow easily sort filter studies commonalities differences. make much easier identify factors covariates subgroup meta-analyses.","code":""},{"path":"template.html","id":"outcome-suggest","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.4 Setting up Outcome or Diagnoses Suggestions","text":"Setting suggestions Outcomes (Diagnoses, Diagnostic Accuracy project) similar setting Arms, though things think .first principle setting Outcomes Diagnoses tab suggest outcomes interest. Authors generally report many different outcomes, may interest project. Eager extractors people new carrying systematic reviews may mistakenly think need extract every outcome reported study. , set suggestions ahead time, can focus avoid wasted time.","code":""},{"path":"template.html","id":"setting-up-outcomes","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.4.1 Setting Up Outcomes","text":"Suggest Domain: outcome measurement interest. instance, PICO question “Among children adolescents, effectiveness multi-component weight management program, compared single-component interventions, bringing improvements weight status?”, want enter “weight status” suggestion number different ways measuring weight status: BMI (body mass index), percent weight change, weight change, percent body fat, etc. , use specific types measurements Domains rather general outcomes (like weight status).\nContinuous variables numeric variables infinite number values two values. example, BMI can take numeric value (e.g., 25.2, 25.3, 25.4)\n\nCategorical variables contain finite number categories distinct groups. example, US Centers Disease Control BMI Categories (underweight, normal weight, overweight, obese).\nalso discrete (counting) variables (e.g., numeric variables countable number values two values–like number hospital visits year), VADRR typically treat discrete variables continuous.click Suggest Type Domain dropdown, ’ll see options.\nBMI (continuous) outcome, SRDR+ automatically set data input structure Results tab “expect” mean, standard deviation number analyzed.\n\nBMI Category (categorical) outcome, SRDR+ automatically set data input structure Results tab “expect” number “events” number analyzed.\nSuggest Specific Measurements Suggest Timepoints fields? useful project focusing specifically certain measurements (e.g., extracting visual analog scale measures pain excluding types pain measurements), project interested specific timepoints (e.g., Baseline one-year outcomes ignoring timepoints). found best let data extractors capture specific measures timepoints reported authors selected studies focus differentiating specific measures timepoints analysis phase.","code":""},{"path":"template.html","id":"setting-up-diagnoses","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.4.2 Setting up Diagnoses","text":"case missed section setting Diagnostic Accuracy template, see section 5.2.2 resource. Hint: don’t see Diagnoses tab (, rather, see Outcome tab), means set project right. Pop back earlier section see set template Diagnostic Accuracy project.","code":""},{"path":"template.html","id":"other-fields","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.5 What Other Fields Do I Need to Extract?","text":"three tabs need set extract data articles: Sample Characteristics, Outcome Details, Risk Bias Assessment.","code":""},{"path":"template.html","id":"sample-characteristics","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.5.1 Sample Characteristics","text":"\nAge participants\n\nSex (/gender) makeup sample\n\nN recruited (likely different N analyzed ’ll capture Results tab)\n\nDropout rate\nAdditionally, likely want add questions specific question study population. might ? Think sample characteristics might possibly affect results study., take time think sample characteristics might plausibly affect results. Best capture front wish later!","code":""},{"path":"template.html","id":"outcome-details","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.5.2 Outcome Details","text":"Note example , confounding variables question (Question 1) free text since authors statistically adjust broad range variables. project one two key confounders adjusted , may able get structured question (e.g., radio button checkbox).Question 2, know ahead time tools commonly used measure body composition area research. , can use structured question. unfamiliar field don’t know common measures, pay close attention full text screening. learn full text review can help structure template. always, plan ahead!","code":""},{"path":"template.html","id":"risk-of-bias-assessment","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.5.3 Risk of Bias Assessment","text":"\nmanually\n\nautomatically\norder manually set risk bias questions, create list questions just tabs. recommend using approach work closely instrument guidance document ensure correct structure well provide contextualized instructions analysts.However, order make life little easier, VADRR provides structured entry method commonly used risk bias instruments. available instruments automatic set :\nRevised Cochrane risk--bias tool randomized trials (RoB 2)\n\nRoB 2.0 Tool (cluster randomize, parallel group trials)\n\nCochrane ROB (original)\n\nJadad Controlled Clinical Trials 17:1-12 (1996) (recommended)\n\nRisk Bias Non-randomized Studies–Interventions (ROBINS-) assessment tool (Cohort-type studies)\n\nModified Newcastle-Ottawa Quality Assessment Scale – Case Control Studies\n\nModified Newcastle-Ottawa Quality Assessment Scale – Cohort Studies\n\nEPC (AHRQ Evidence-Based Practice Centers) Common Dimensions\n\nMcMaster Quality Assessment Scale Harms (McHarm)\n\nStard – quality diagnostic tests (recommended STARD writing guide true risk bias tool)\n\nQUADAS2\nTwo additional points note:\ntool contains “bias” question (e.g., original Cochrane RoB) want specific risks relevant particular project.\n\nneed repeat questions (e.g., evaluate different outcomes separately– see ).\ncan add one tool. relevant project contains one type study design. instance, project includes randomized non-randomized interventions, may want add Cochrane ROB 2.0 ROBINS-.Happily, can add multiple risk bias tools Risk Bias tab. confusing data extractors since may know exactly questions apply designs. can get around problem including screening question top Risk Bias tab using Dependencies function turn questions apply particular design (see VADRR 5. Tips Creating Data Extraction Template). little bit work setting , remember, didn’t build risk bias questions hand, ’s terrible.","code":""},{"path":"template.html","id":"repeating-the-question-by-arm-or-outcome","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.5.4 Repeating the Question by Arm or Outcome","text":"Imagine scenario: needing capture different demographic characteristics different arms (e.g., sex distribution different arm). Additionally, needing capture particular mix intervention components different arms. means need repeat questions Sample Characteristics tab Arm Details tab arm.can simply repeat question arm (duplicate questions intervention control arms), problem studies two arms (e.g., two intervention arms plus control arm).better way capitalize functionality within VADRR allows link tabs (dependent tabs) tabs (independent tabs: Arms Outcomes) questions repeat often needed. means set question , repeat within dependent tab often necessary.functionality comes play.\nrepeat every question Arms Details tab arm (e.g., different interventions carried different arms),\n\nrepeat every question Sample Characteristics tab arm,\n\nrepeat every question Outcome Details tab outcome (e.g., want capture covariates separately outcome),\n\ncarry separate risk bias outcome rather whole article.\nnow show setup extraction template .","code":""},{"path":"template.html","id":"repeating-arm-details-and-sample-characteristics-questions-for-each-arm","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.5.4.1 Repeating Arm Details and Sample Characteristics Questions for Each Arm","text":"default setting VADRR Arm Details Sample Characteristics tabs., rather create question twice extraction template, question needs entered template repeat arm. particularly handy number arms might vary (e.g., 2 arms versus 3 arms).settings place, questions Arm Details tab repeat.Note: projects comparing arms, likely want keep VADRR default settings place.","code":""},{"path":"template.html","id":"repeating-outcome-details-questions-for-each-outcome","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.5.4.2 Repeating Outcome Details Questions for Each Outcome","text":"ensure Outcome Details question repeat every outcome, use pulldown link Outcomes tab.Note: , earlier example, want separate structured questions capture measurement options different outcomes, want repeat question (e.g., measurement tools capture body composition different measurement instruments used capture pain level).","code":""},{"path":"template.html","id":"separate-risk-of-bias-assessment-for-each-outcome","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.5.4.3 Separate Risk of Bias Assessment for Each Outcome","text":"\n“Allow separate risk bias ratings outcome account outcome-specific variations detection bias selective outcome reporting bias. Categories outcomes, harms benefits, may different sources bias.” (See Assessing Risk Bias Individual Studies Systematic Reviews Health Care Interventions)\nSimilarly, Cochrane requires separate risk bias evaluation outcome., within VADRR?Linking Outcomes done way described : simply use pulldown link Outcomes tab.Note: time writing, even ROB section linked Outcomes tab, questions automatically repeat. Thus, use workaround.every question needs repeated every outcome. example, using Cochrane ROB 2.0 risk bias tool, possible questions regarding blinding participants differ outcome (e.g., trial combines drug treatment [easily blinded] cancer along behavioral intervention [blinded] quality life outcome), difficult imagine randomization allocation concealment questions differing study outcome. However, questions pertaining specifically outcome assessment (e.g., Domain 6 ROBINS-E instrument) almost certainly differ depending outcome question.Thus, questions need repeated key outcome, questions .Work around solution: set questions (example, using Add questions pre-defined list button, hand), can manually add additional questions relevant different outcomes. following example, added Cochrane ROB 2.0 questions using “Add questions pre-defined list” button. want ask question “predicted direction bias measurement outcome?” question separately two separate outcomes, “chemical failure” (.e., return cancer biomarkers treatment) “quality life”.\nFirst, scroll question repeated.\n\nSecond, alter text question specify outcome question refers .\n\nThird, click Duplicate link create duplicate question (new question appear end ROB questions.\n\nFourth, now scroll new question change “Chemical failure” “Quality Life”:\n\nOptional: want new question follow duplicated question, can use Position pulldown change question order. example, since “Chemical failure” question #34, can change “Quality Life” question #35.\nNote: use caps examples necessary. convention use clearly signal extractors/evaluators different outcomes.Important Considerations Evaluating ROB OutcomeWhich questions repeated? clear direction , , general, consider specific questions (Domains) within risk bias tool using determine likely possibly going different assessments different outcomes. important discuss plan team especially team methodologist ahead time determine risk bias questions repeated project.optimal placement repeated questions? , direction . may easier analysts consider questions sequentially, case likely want keep repeated questions next risk bias instrument. Alternatively, repeated questions end risk bias tool. good strategy get input team regarding structure find beneficial.Can assume analysts understand evaluate different outcomes? word: Training team discussion differences different outcomes (measured, possible directions bias, etc.) critical. best training ahead time example articles. Review analyst responses discuss differences.","code":""},{"path":"enter-data.html","id":"enter-data","chapter":"7 Entering Data","heading":"7 Entering Data","text":"log VADRR, taken Projects page. list projects member . number options interacting project:\nClicking project title open Project Dashboard (see )\n\nEdit Forms opens options go either Screening Form Builder Extraction Form Builder\n\nScreening opens options go either Abstract Screening Full-text Screening tool (number parentheses indicates number citations currently screening status)\n\nExtractions opens options go either Data Extractions (analysts enter data articles) Comparison Tool (allows consolidators harmonize extractions create extraction record). number parenthesis indicates number citations currently assigned data analysts.\n\nExport & Import opens options Quick Export menu customizable version Export Import tools\n\nPublication opens options Request Publication project SR-360 (platform sharing review summary digitally interactively)\nTypically, analyst working extracting articles use Extractions / Data Extractions taken page work.","code":""},{"path":"enter-data.html","id":"entering-data-and-registering-progress","chapter":"7 Entering Data","heading":"7.1 Entering Data and Registering Progress","text":"Entering data simple VADRR.Just click whichever tab want work data form open. Simply begin enter data!\nTip 1: best PDF article open extraction. Copying pasting unstructured fields help prevent typos!\n\nTip 2: need enter information Arms Outcomes tabs can enter data Results tab (dependent tab).\n\nTip 3: Save Risk Bias tab last. much better position critically appraise study detailed understanding study (get extracting information tabs).\n","code":""},{"path":"enter-data.html","id":"entering-arm-information","chapter":"7 Entering Data","heading":"7.2 Entering Arm Information","text":"However, rather begin typing names arms, first click Suggested Arms button. project set standard arm names (good idea: see VADRR 5.2. Setting Arm Diagnostic Test Suggestions), set pre-set arm options choose . Simply clicking one suggested arms populate arm Name Description.\nContinue arms added.pointed Section VADRR 5.2. Setting Arm Diagnostic Test Suggestions, may want leave Description field blank enter descriptive detail arms Arm Details tab.","code":""},{"path":"enter-data.html","id":"setting-up-outcomes-1","chapter":"7 Entering Data","heading":"7.3 Setting Up Outcomes","text":"way selected list Suggested Arms, similarly want select list Suggested Outcomes.Note: team projects, data extractors select list important. prevent multiple extractors naming outcome differently within article facilitate Consolidation analysis later.\nNow, notice several fields need specified Outcome:\nType Outcome: field pre-populated type measure (continuous categorical). see anything Type Outcome field, means set Type Outcome constructing template. may want return template fix proceeding. , reason, entering Outcome previously defined template, use pulldown select either continuous categorical.\n\nDomain: selecting Suggested Outcome popup, field also pre-populated. , reason, entering Outcome previously defined template, simply type name outcome. , recommend directly typing Domain field. cause problems later Consolidation analysis phases project.\n\nSpecific Measurement: may (need ) enter specific measurement . instance, several different tools measuring pain sometimes authors report one article. “pain” outcome, may want enter name tool (e.g., Visual Analogue Scale, Faces Scale, etc.). Note, select outcome Suggested Outcomes popup twice. , set template pain scales Specific Measurement, need manually enter Pain different Specific Measurement one previously entered.\n\nPopulations: Sometimes authors present results broken sub-populations. instance, childhood obesity study may report results girls boys separately. Simply rename existing Population (“Participants” image ) click +Add Population link just existing population name add another population. can particularly handy diagnostic test outcomes results reported separately different organisms. Note: results reported entire sample, can leave Population field just .\n\nTimepoints: field important. SRDR+ uses Timepoints help structure data entry structure Results tab. set wrong, able enter data correctly Results tab. first Timepoint (“Baseline”) pre-populated can changed. want add separate timepoint (using +Add Timepoint link) measurement timepoint reported article (e.g., Baseline, 1 month, 3 months). best way enter Timepoints use number name unit Unit field. example:\nentered appropriate information fields, click Save. Note, continuous outcomes show green categorical outcomes show blue upper box entered.","code":""},{"path":"enter-data.html","id":"entering-results","chapter":"7 Entering Data","heading":"7.4 Entering Results","text":"VADRR designed take information entered Arms tab information entered Outcomes tab create data entry matrix . VADRR typically default common categorical continuous measures reported research studies. , BMI Category outcome example , can see VADRR created matrix :separate column ArmHas separate entry spaces timepointHas “guessed” statistics likely reported timepoint","code":""},{"path":"enter-data.html","id":"entering-descriptive-statistics","chapter":"7 Entering Data","heading":"7.4.1 Entering Descriptive Statistics","text":"Descriptive statistics statistics arm timepoint. enter values arm time point, simply type (copy paste) values article appropriate cell data table. Note: VADRR immediately automatically save data type cells, see cell background turn pale yellow enter small “saved” message appear. rare, times heavy server traffic, save may take moment.Important Tip: best enter numbers Results data fields. make data cleaning bit easier. instance, “n=54” entered Total (N analyzed) field, data downloaded, need strip “n=” order analysis. Save little time enter numbers.Now, authors often report results using descriptive statistics VADRR “best guess”. instance, defined outcome continuous, VADRR typically create data entry cells n analyzed, mean, standard deviation (). However, often data normally distributed authors may report median minimum/maximum 25th/75th percentile (also called Interquartile range IQR). happens, enter data, ’ll need edit measures.click (edit measures), window open able either select commonly reported statistics (simply select boxes) add different measure.entered new measures, click update see outcome statistics changed main data entry table.","code":""},{"path":"enter-data.html","id":"entering-within-arm-comparisons","chapter":"7 Entering Data","heading":"7.4.2 Entering Within Arm Comparisons","text":"show enter within-arm comparisons, -arm comparisons Net (.e., within--) arm comparisons, might good review mean terms presenting concrete examples.Gentle Review Different Types Statistical Comparison\nFirst, let’s look table (taken Díaz et al 2010).\nmeasures columns indicated yellow box descriptives. simply statistics timepoint arm. talked section.\n\nmeasures columns indicated purple box within-arm measures. words, change scores individuals arm () baseline 6-months (b) baseline 12-months. instance, mean weight individuals “Lifestyle” arm decreased -3.7±3.3 kg baseline 6-months.\n\nmeasures columns indicated black box Net measures (sometimes called within--measures). differences change scores arms given time point. , instance, saw “Lifestyle” arm decreased ’s average weight -3.7±3.3 kg 6-months “Control” arm increased mean weight 2.7±3.0 kg. difference changes 6-months -6.4 (95% CI: -8.4, -4.5) — left column black box.\nTip meta-analyses: Often, carrying meta-analysis, generating Net differences within-arm changes. words, ’ll generally enter data matrix meta-analysis descriptives, within-arm change scores (standard deviation change scores). instance, data matrix meta-analysis R , values purple columns descriptives, mean change scores experimental (abbreviated “”) control (abbreviated “Mc”) arms.means time can (, authors report ), best enter change scores VADRR., let’s look .click Add Comparison button see two dropdowns:select timepoint comparisons authors report. Using Table 2 Diaz et al article (), ’m going focus 6-month changes (green column)., click Save Comparison see new data entry matrix change scores baseline 6 months.Notice can also edit measures need (“edit measures” link data entry cells). Now, thing set Baseline 12 mo outcome comparison.Remember: carrying meta-analysis, can capture within-arm results bother capturing timepoint descriptives.","code":""},{"path":"enter-data.html","id":"entering-between-arm-comparisons","chapter":"7 Entering Data","heading":"7.4.3 Entering Between Arm Comparisons","text":"-arm comparisons typically just differences arm measures single timepoint.Typically, wouldn’t bother entering -arm comparisons used directly meta-analysis. However, couple situations want set -arm comparisons:\nOccasionally authors may report values. Thankfully, rare meaningful special circumstances\n\nmay want need set Net arm comparisons (see section 8.4.4)\n\nmay capturing relative effect measures (e.g., odds ratios hazard ratios), special types -arm comparisons can used meta-analyses.\nset -arm comparisons, click Add Comparison button., dropdown appear Add Comparison button .Since two arms Diaz et al article, ’m going select treatment (response) arm dropdown. , another box appear can select comparison arm., ’ll click “Save comparison” button see data entry cells comparison:","code":""},{"path":"enter-data.html","id":"special-circumstance-setting-up-relative-measures","chapter":"7 Entering Data","heading":"7.4.3.1 Special Circumstance: Setting Up Relative Measures","text":"Depending question answering systematic review, may want extract relative measures (like odds ratio, risk ratio, hazard ratio, etc.) arm comparisons.Important note: capture relative effect measures, outcome need defined categorical variable. may seem odd something like hazard ratio, relative measures derived categorical comparisons treated categorical variables VADRR data extraction.’ll set comparisons just . Since treating relative measures categorical variables, ’ll see different measures.clicking “edit measures” link, window open different relative measures.","code":""},{"path":"enter-data.html","id":"entering-within-and-between-net-arm-comparisons","chapter":"7 Entering Data","heading":"7.4.4 Entering Within-and-Between (Net) Arm Comparisons","text":"Sometimes may want capture within--arm comparisons (also called Net Comparisons). noted , differences within-arm changes two comparison arms. can think difference change trajectories two arms.might need enter ? just said can carry meta-analysis using within-arm change values, want bother Net comparisons?\nSometimes, author report.\n\nAlso, can carry meta-analysis using Net comparisons (indeed, Net comparison also known “treatment effect” value see forest plot meta-analysis).\n\nauthors report net comparisons, need carry meta-analyses pre-calculated effect. means need use statistical software calculate values articles report net comparison statistics meta-analysis.\nexcellent overview difference using “Pre-calculated effect size data” (calling Net comparisons) versus “Raw effect size data” (within-arm change data), see Chapter 4 Harrer et al’s free online book Meta-Analysis R: Hands-Guide. See chapter 17 helpful resources calculating values need meta-analysis.enter Net comparisons?already set within-arm -arm comparisons, Net comparison data entry cells already set . comparisons, can click “edit measures” change measures authors report.","code":""},{"path":"results-out.html","id":"results-out","chapter":"8 Getting Your Results Out of VADRR","heading":"8 Getting Your Results Out of VADRR","text":"Getting data VADRR simple.top navigation bar, look Export & Import pulldown. click , see two options:purposes, quick menu sufficient, go options.two options:Download data data extraction template: produces Excel spreadsheet several tabs (one tab data extraction template plus several capture different statistics). example downloaded spreadsheet look like:\nNote: Download tasks queued server. means download may immediate (especially large dataset). receive email (using email registered VADRR) task completed. large project server particularly busy, need patient.Download data screening tools: Excel file contains data collect via Screening tools (Abstract screening Full-text screening). can helpful want review results either screening tasks.","code":""},{"path":"results-out.html","id":"export-import","chapter":"8 Getting Your Results Out of VADRR","heading":"Export & Import","text":"full Export & Import option provides ability download data (), also provides ability import data (example, data extraction template created different platform like Distiller SR Covidence) well option able share data VADRR directly another provider website via API token.updated data since last download, want use top purple buttons. simply wanting another download previous date, can click Download link lower right box.","code":""},{"path":"dashboard.html","id":"dashboard","chapter":"9 Using the Project Dashboard","heading":"9 Using the Project Dashboard","text":"\nProject Overview: Dashboard provides broad overview/summary project progress, showing total number citations within phase project\n\nCitation Detail: detailed, -depth views individual citations: status details\n\nChange Citation Status: ability manually move citations different phases. Although citations change status automatically based tasks completed, citation status can manually changed, may useful certain circumstances (discussed )\n\nMake Extraction Assignments: ability assign extractions analysts groups analysts\n","code":""},{"path":"dashboard.html","id":"understanding-project-phases","chapter":"9 Using the Project Dashboard","heading":"9.1 Understanding Project Phases","text":"VADRR, four different “phases” stages citation can given time:\nAbstract Screening: stage, citations abstract/title screened inclusion exclusion project.\n\nFull-text Screening: stage, citations full-text reviewed inclusion exclusion.\n\nExtraction: stage, citations assigned analysts data extraction.\n\nConsolidation: final stage. Assuming double () extraction, Consolidation stage third extraction (“extraction record”) created, harmonizing existing extractions.\nWithin phases, citation can different statuses (explained ).benefit Project Dashboard allows carry track project assembly line batch approach.\nabstract/title screening complete, full-text screening begins,\n\nfull-text screening complete, extraction begins,\n\nextraction complete, comparison consolidation (QA step) begins.\nVADRR, soon citation screened title/abstract screening phase, moves (automatically) full-text screening phase. , even though screeners may still working title/abstract screening, work can begin immediately full-text screening. Similarly, citation screened full-text screening phase, moves automatically Extraction phase. Thus, citation can assigned extraction even though bulk articles still title/abstract screening phase.\ncan think difference “batching” versus “pipeline” approach.\nbenefit approach can substantially speed evidence synthesis process avoid members team (e.g., analysts) waiting members team complete tasks (e.g., waiting screeners finish).","code":""},{"path":"dashboard.html","id":"statuses-within-project-phases","chapter":"9 Using the Project Dashboard","heading":"9.1.1 Statuses within Project Phases","text":"Within phase, citation can different statuses. now explain .","code":""},{"path":"dashboard.html","id":"phase-i-titleabstract-screening","chapter":"9 Using the Project Dashboard","heading":"9.1.1.1 Phase I: Title/Abstract Screening","text":"five statuses citations within phase:Unscreened [asu, abstract screen unscreened]: citations yet screened awaiting screening screening team.Partially screened [asps, abstract screen partially screened]: citations screened one screener awaiting second screening. Note, however, articles need human double screened one screeners AI. partially screened citations low probability included based AI, system prioritize double screened second human (detail AI-assisted screening, see VADRR Understanding Using Machine Learning Results).conflict [asic, abstract screen conflict]: articles either (1) human screeners agree whether include exclude, (2) one screeners marked status “maybe.” citations reviewed lead analyst (designated team member) status resolved. Note: citations “conflict” status used AI generate model inclusion.Accepted: articles marked inclusion screeners, move automatically full-text screening phase. number accepted articles remain static articles screened.Rejected [asr, abstract screen reject]: articles either rejected screeners manually marked “rejected” (e.g., end screening phase, project lead lead analyst may manually move citations partially screened status low probabilities included reject [asr] status).","code":""},{"path":"dashboard.html","id":"phase-ii-full-text-screening","chapter":"9 Using the Project Dashboard","heading":"9.1.1.2 Phase II: Full-text Screening","text":"Similar title/abstract screening, five statuses within full-text screening phase.Unscreened [fsu, full-text screen unscreened]: citations yet full-text screened awaiting screening project lead designated team member.Partially screened [fsps, full-text screen partially screened]: citations double screened full-text phase, citations screened one screener awaiting second screen. Note, full-text screen done single person, status used.conflict [fsic, full-text screen conflict]: double full-text done, citations disagreement screeners regard inclusion status listed . one team member responsible full-text screen, status used.Accepted: articles marked inclusion move automatically exraction phase. number accepted articles remain static articles screened.Rejected [fsr, full-text screen reject]: articles either rejected analysts manually marked “rejected.”","code":""},{"path":"dashboard.html","id":"phase-iii-extraction","chapter":"9 Using the Project Dashboard","heading":"9.1.1.3 Phase III: Extraction","text":"\nNeeds Extraction [ene, extraction needs extraction]: articles awaiting assignment analysts project lead project manager (see VADRR 8.3).\n\n\nProgress [eip, extraction progress]: articles currently assigned analysts extraction.\n\nRejected [er, extraction rejected]: Occasionally, articles may make screening phase ultimately deemed unsuitable project. can manually marked rejected.\n\nComplete [ec, extraction complete]: provides record number citations fully extracted analysts assigned citation. analysts assigned citation mark extraction tabs Complete, citation automatically moves cnc (needs consolidation) status ene counter advances.\nProject Management Tips: Project managers regularly monitor ene (Needs Extraction) status, need manually assigned analysts.","code":""},{"path":"dashboard.html","id":"phase-iv-consolidation","chapter":"9 Using the Project Dashboard","heading":"9.1.1.4 Phase IV: Consolidation","text":"four statuses Consolidation phase:Needs consolidation [cnc, consolidation needs consolidation]: articles double extracted marked complete analysts. need assigned lead analysts designated team members comparison consolidation.progress [cip, consolidation progress]: articles consolidated record created marked complete consolidator.Rejected [cr, consolidation rejected]: Occasionally, citation may rejected even consolidation. status can used indicate removal consolidated extraction project (note, consolidated record remains, marked excluded).Completed [cc, consolidation completed]: consolidation marked Complete, moved final status.Project Management Tip: Project managers regularly monitor Needs Consolidation [cnc] status. consolidation task assignments currently made within VADRR system, keeping track assigned consolidation tasks key project progress.","code":""},{"path":"dashboard.html","id":"viewing-and-changing-citation-details-and-status","chapter":"9 Using the Project Dashboard","heading":"9.2 Viewing and Changing Citation Details and Status","text":"\nCheck status particular article,\n\nIdentify duplicates slipped previous rounds deduplication,\n\nIdentify articles particular status,\n\nSee details regarding screening decisions,\n\nManually make changes citation status,\n\nMake multiple extraction assignments multiple analysts.\nfirst three functions achievable simply searching sorting articles listed table.latter three functions utilize table functionality.","code":""},{"path":"dashboard.html","id":"reviewing-screening-decisions","chapter":"9 Using the Project Dashboard","heading":"9.2.1 Reviewing Screening Decisions","text":"","code":""},{"path":"dashboard.html","id":"changing-citation-status","chapter":"9 Using the Project Dashboard","heading":"9.2.2 Changing Citation Status","text":"Even though citations move phases automatically, depending actions taken (e.g., screened , extraction completed, etc.), citation status can changed manually time using Citation Lifecycle Management tool.couple reasons manually changing status citation:Promoting “Pearls”: Often, systematic review begin handful studies already identified pertinent topic. (Indeed, research reported pearls may impetus question project.) often referred “pearls”. need go traditional screening process can “promoted” Accepted status start. benefit promoted pearls included initial AI modeling inclusion.Additional Questions Added: projects, particularly living reviews goal monitor development research topic, new question may added project fact. Already completed consolidated citations “demoted” back extraction status additional outcomes originally collected can now extracted. instance, project examining relationship exposure airborne hazards interstitial lung disease, question pulmonary function (perhaps “upstream” intermediate effect) may added. case, demoting citations contain pulmonary function data allow additional outcomes extracted.\nClick Acceptance accept article either phase. promote citation next phase. AI Abstract screening use information train model.\n\nClick Rejection remove article screening queue move Reject status (either asr fsr). AI use manually set “reject” status inform screening model.\n\nClick Acceptance approve citation (just extraction) , case Extraction, move Consolidation phase (enter cnc status). equivalent project lead lead analyst certifying citation approved move next phase status.\n\nClick Rejection remove citation phase chain completely. Note: “demote” article (.e., move Consolidation status Extraction status–see ), pulls pipeline. probably rarely used Extraction phase can occur article meet inclusion criteria “slips ” Abstract Full-text screening phases. Sometimes, clear article meet criteria depth reading occur extraction. Even rare Rejection Consolidation phase.\n“demote” article Consolidation Extraction status:\narticle consolidated, possibility may need additional extraction work (.e., new outcome added project).change status backward Consolidation Extraction, use controls bottom Project Dashboard. Rather, strategy project lead lead analyst identify already extracted articles contain outcome interest , Extractions page, toggle tab tabs need additional work Complete Draft.reduce Progress bar Extractions page analysts need notified additional work citation needs completed.","code":""},{"path":"dashboard.html","id":"extract-tasks","chapter":"9 Using the Project Dashboard","heading":"9.3 Using the Project Dashboard to Assign Extraction Tasks","text":"click Extraction button, window open list analysts project.Tip making analyst assignments:Assuming working two analysts, can sometimes challenge split extraction assignments easily making sure good mix different analysts extracting citation., can use Extraction assignment tool make double extractions.Note: ways , found straightforward way (less) randomize assignments ensuring reasonably even distribution tasks across analysts.","code":""},{"path":"alt-method.html","id":"alt-method","chapter":"10 Alternative Method for Assigning Articles for Extraction","heading":"10 Alternative Method for Assigning Articles for Extraction","text":"uploaded article Citations systematic review (Section 3: Uploading Article Citations) built extraction template (Sections 5 5.5), ready begin assigning extractions.recommend using Project Dashboard article assignments, alternative methodBefore data extractors can begin actually enter information different studies, ’ll first need make Extraction assignment (, assign particular articles particular data extractors).Begin extraction simply clicking Extract Data link left side cite record!Note, different team members see citations assigned . project leader, see extractions.Reassign Link ?may noticed “Reassign” link right progress bar. reassigning extraction different analyst, can used reassign extraction different citation.might want ? uncommon protocol abstract study published prior publication full article. include abstracts project extract data can abstract, may want update extraction (adding additional detail) full text article published. Rather two records study, allow assign extraction full article without duplication.","code":""}]
