[{"path":"index.html","id":"about","chapter":"About","heading":"About","text":"guide extract data systematic reviews VADRR.","code":""},{"path":"start.html","id":"start","chapter":"1 Getting Started","heading":"1 Getting Started","text":"first thing ’ll need get started register VADRR.VADRR currently available general public. like access VADRR, please contact scott.parrott@rutgers.eduThat’s takes! Now ready begin setting project creating data extraction template.","code":""},{"path":"setup.html","id":"setup","chapter":"2 Setting Up Your Project","heading":"2 Setting Up Your Project","text":"three things need set project SRDR.Create project enter basic project informationCreate key questionsEnter project members","code":""},{"path":"setup.html","id":"creating-your-project","chapter":"2 Setting Up Your Project","heading":"2.1 Creating Your Project","text":"registering VADRR account, ’ll sent email confirmation. ’ve confirmed registration logged , ’ll taken Projects page. won’t see projects listed just yet. , ’ll need create first project. , just click Create Project button.Next, ’ll prompted give new project name (want) brief description. , just click Submit button create project.Note pulldown just Submit button populated default “Create empty project.” However, evidence extractions created platforms (e.g., Distiller SR) can archived VADRR. pulldown allows users archive projects.creating new project, need worry using .click Submit button, taken page can add details project.","code":""},{"path":"setup.html","id":"enter-your-key-questions","chapter":"2 Setting Up Your Project","heading":"2.2 Enter Your Key Questions","text":"Next, want set key questions project. Click Key Questions option Project Info tab.take page set Key Questions (e.g., PICO questions) project.entered Key Questions, ’ll option begin building data extraction form. ’ll find button bottom right Key Questions page., begin creating data extraction template, may want add additional members team. can always add team members later, setup, let’s go ahead see add members set project roles.","code":""},{"path":"setup.html","id":"enter-project-members-and-set-their-roles","chapter":"2 Setting Up Your Project","heading":"2.3 Enter Project Members and Set Their Roles","text":"Just Project Information Key Questions, ’ll find Members Roles link top page Project Info tab.open Members & Roles page, see following.walk options now.First, need enter new team member’s ID (email used registered VADRR) project. someone registers VADRR, email becomes ID.Second, ’ll define new team member’s role. role ability different things project.    Leaders: Since set project, default Leader access functionalities within VADRR. can one Leader per project. However, want careful designating leaders. can change anything project (even delete project!), can cause confusion problems. especially true leaders experience systematic review projects VADRR. , judicious designating someone Leader.\n   Consolidators: members whose primary job serve referee duplicate (triplicate, etc.) extractions. instance, articles project double extracted (.e., two people extracting article quality assurance purposes), Consolidator person adjudicate extractions disagreement extractors. Often, want third person involved initial data extractions serve quality check.\n   Contributors: members data extractors project. can also serve screeners project.\n   Auditors: individuals make changes project, can view project (e.g., additional quality assurance step).\n   Experts: screening tool (see VADRR 4.0.1 Screening Tool Resources Team Leaders), ability differentiate topical experts novices. Identifying topical experts can ensure article screened without least one expert viewing article.full description different things different roles can .Finally, ’ve set member’s role, just click Save Changes.Note, ever need add new member project, can always add clicking Project Details tab selecting Members & Roles link. can also add/modify Keywords Project Information time well.","code":""},{"path":"upload.html","id":"upload","chapter":"3 Uploading Article Citations","heading":"3 Uploading Article Citations","text":"can assign screening tasks assign articles extraction, need upload article citations VADRR. page provides instructions .enter citations article Project Info / Citations link.now Citations page. couple ways add citations. can add citations one time bulk list citations reference manager export file.","code":""},{"path":"upload.html","id":"adding-citations-one-at-a-time","chapter":"3 Uploading Article Citations","heading":"3.1 Adding Citations One at a Time","text":"Click Add Citation button.\nclick Create Add Citation link, dialogue box opens.now couple options:\n|\n|First, can manually type citation information fields. recommend use option articles Pubmed ID number.Second, can enter Pubmed ID number top Accession Number field click Fetch Pubmed link.click Fetch link, VADRR populate citation fields automatically.","code":""},{"path":"upload.html","id":"adding-many-citations-from-a-file","chapter":"3 Uploading Article Citations","heading":"3.2 Adding Many Citations from a File","text":"collected citations reference manager file comma delimited spreadsheet file, can upload many citations .important know types files upload (trying upload wrong type file work, may import junk citation list). , sure look types files can upload.types files can upload.Note clicking one file type links listed download template can enter information articles. entered reference information file template, just save drag drop file Drop Files Upload box.Special Note Endnote Export: using Endnote 20 later, may want export selected references text file use RefMan (RIS) Export output style. Use following settings:citation export file created, can simply drag drop box.","code":""},{"path":"upload.html","id":"confirming-correct-citation-format","chapter":"3 Uploading Article Citations","heading":"3.3 Confirming Correct Citation Format","text":"uploaded file, now need confirm file cite structure correct.citations upload immediately. VADRR require confirm detected format file correct. , click Confirm.VADRR one confirmation step: show example uploaded citations. format looks correct, click Start Import button.now receive message file uploaded. upload jobs queued server, large files can take time. receive email confirmation upload completed.small number references, can click refresh button, see newly uploaded citations.upload complete, can navigate back citations page.several options dealing uploaded citations.can reorder citations clicking sort buttons column.can edit delete citations using controls right side page.","code":""},{"path":"upload.html","id":"deduplication","chapter":"3 Uploading Article Citations","heading":"3.4 Deduplication","text":"Even though likely deduplicated citations within reference manager, deduplication often imperfect. , don’t surprised find VADRR detected duplicate references.duplicate references, see option top page deduplicate citations. can click deduplicate.","code":""},{"path":"vadrr-screener.html","id":"vadrr-screener","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4 Screening: Insructions for Screening Set Up (Project Leads)","text":"chapter meant team members setting screening tasks. instructions screeners, see XXXFor many systematic reviews, thorough search result hundreds thousands potential articles. Institutes Medicine guidelines indicate title/abstract screening carried two members review team working independently (see Standards Finding Assessing Individual Studies Standards Finding Assessing Individual Studies – Finding Works Health Care – NCBI Bookshelf.Double-screening thousands titles abstracts can difficult time-consuming.However, VADRR incorporates screening tool uses advanced machine learning (ML) models help team efficiently identify studies appropriate project.ML screener uses inclusion/exclusion decisions team members create prediction (calculate probability) score every article. rearranges articles pull ones likely included front screening queue.ML model relies team member screenings formulate model, n=100 initial screens needed generate model. , won’t see results right away. However, “pearls” (articles already pre-identified inclusion) manually marked inclusion Project Dashboard (see 11.0 Using Project Dashboard), factored ML model default. , beginning project, already set “pearl” articles, want manually mark inclusion Project Dashboard.tutorial, walk different screening setup options, screen, use ML model results make decision regarding stop screening.Yes, ’s right, may need screen thousands articles! meet stopping criteria (), team can stop screening (letting ML model “screen” rest ).part tutorial set two sections:4.1 Resources Team Leaders: section provides information set screening team, set screener meets team’s needs (many options ), track progress.4.2 Resources Screeners: section provides basic instructions members screening team–effectively use tool.","code":""},{"path":"vadrr-screener.html","id":"leaders","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1 Screening Tool Resources for Team Leaders","text":"following, provide step--step instructions project managers set carry title/article screening projects.","code":""},{"path":"vadrr-screener.html","id":"first-step-upload-your-citations-and-then-find-the-abstracttitle-screener","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.1 First Step: Upload Your Citations and Then Find the Abstract/Title Screener","text":"can use Abstract Screening tool, need upload citations (see 3.0 Uploading Article Citations). done , citations automatically entered Abstract Screening Unscreened status Project Dashboard.citations appear , ready set Abstract Screener.get Abstract Screener, simply click Screening link upper navigation bar select Abstract Screening.getting started, need set screening—, determine team screen screen.","code":""},{"path":"vadrr-screener.html","id":"deciding-on-the-screening-team-and-approach","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.2 Deciding on the Screening Team and Approach","text":"working team, screening, need determine:double screening?need pilot screening round?need screeners experts?answers answers “yes”. However, smaller projects (e.g,, class project), criteria may apply.’ll walk .","code":""},{"path":"vadrr-screener.html","id":"double-screening","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.2.1 Double Screening","text":"noted , standard practice double-blind screen citation inclusion/exclusion.means need least two screeners, can certainly work (may help step process move faster). Ideally, least subset screeners deep understanding topical area.","code":""},{"path":"vadrr-screener.html","id":"pilot-screening","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.2.2 Pilot Screening","text":"First, good practice make sure everyone screening team page comes inclusion exclusion. Don’t assume everyone (even experts) completely understand inclusion exclusion criteria. means need :Create detailed instructions including excluding articles: specify criteria related PICO (population? exposures/interventions? comparators? outcomes? language date restrictions? study designs? Etc.)Pilot screen: Rather people simply begin screening, best limited pilot screening. , members screening team screen number articles (usually, 30 articles sufficient).pilot screening, useful meet screeners discuss disagreements reach consensus. able see disagreements using Resolve Conflicts button (see ).","code":""},{"path":"vadrr-screener.html","id":"are-experts-needed","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.2.3 Are Experts Needed?","text":"Ideally, experts topical area serving screeners. However, may also less experienced people team. , may want avoid one article screened two inexperienced individuals. case, need set “Experts” .can Members & Roles page:left team members’ names toggle button. can toggle button indicate experts .Note: smaller project , can single screen automatically expert.several options setting screening team tasks, ’ll walk now.","code":""},{"path":"vadrr-screener.html","id":"setting-up-your-screening-tool","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3 Setting Up Your Screening Tool","text":"Pilot: Use initial training calibration team members. select option, prompted indicate many citations team members assess. N=30 typically sufficient, though may want less depending team.Perpetual Single: citation require one person review, screening continue citations screened. noted , good practice may useful training class projects. Perpetual Double: citation must screened two screeners (combination two screeners ), screening continue citations screened.Perpetual (Expert Needed): citation must screened two screeners, least one must expert. Screening two experts allowed, screening two novices allowed. Screening continue citations screened.Perpetual (Mixed Expert): Two screeners needed citation one must expert, must novice. Two Expert two Novice decisions allowed.Fixed N Size (Single): one screener needed, specified number articles screened (honestly, bit difficult see might apply).Fixed N Size (Double): Double screening (mix Experts Novices), specified number screenings per person. option can useful keep individuals getting overwhelmed (e.g., assigned n=200 cites can “feel” different assigned “many can ”). One downside relies team members actually carry number assigned. screeners volunteers one slow (just things going lives), waiting screen can slow process. Additionally, experience, often people really screening don’t like stop. may consider whether really want put limits folk.Fixed N Size (Expert Needed): least one may two Experts screen article specified N reached.Fixed N Size (Mixed Expert): One Expert One Novice screen citation specified N reached.option choose? noted , small Pilot round ideal. one double screen options meet IOM standards.Deciding perpetual versus fixed: depend team project. found limiting specific number can slow project (limits people want screen , requires screening people busy get screening). highly motivated committed panel screeners, fixed N screening may work fine. Double perpetual generally worked best experience.Experts Novices: mix Experts Novices, likely want choose one options requires least one Expert (allow two Novices screen citation). Using Expert Needed option may allow flexibility cite already one Expert review need “wait” Novice review. members team well trained, one simple double screening options appropriate.Fixed N, many assign? rule , want weigh commitment motivation team. trying keep people feeling overwhelmed, initially assigning n=200 generally good. Note everyone finishes assigned number screenings, need set new screening plan assign next batch. can also achieve much result (without set new screening plan) Double Perpetual simply tell team members screen certain number stop.","code":""},{"path":"vadrr-screener.html","id":"setting-up-rejection-reasons","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.1 Setting Up Rejection Reasons","text":"crucial citation rejection decisions capture reason rejection. table contains settings abstract screening type, see table allows set requirements based user decisions (include reject).","code":""},{"path":"vadrr-screener.html","id":"setting-up-tags","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.2 Setting Up Tags","text":"Tabs multi-purpose labels can used many ways. required use may useful certain circumstances.instance:Identifying background articles. Just citation rejected, may provide useful background information project (e.g., reviews, commentaries, etc.). , may want provide way screeners reject article still mark “background” “interest”.Identifying study purpose: Suppose carrying systematic review multiple questions (e.g., regarding treatment, regarding mechanism, etc.), want presort included articles respective article types. may want require tag included article accepted. instance, following example, tag required decisions (probably needed Yes [include] decisions):extraction screen, tags appear like :, tag use optional, simple projects, may needed.","code":""},{"path":"vadrr-screener.html","id":"using-notes","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.3 Using Notes","text":"Notes also optional can useful “Maybe” decisions. screener indicates maybe, often simply aren’t sure may conflicting reasons include. Getting additional thoughts can help consolidator later make decision regarding inclusion .Setting Notes required Maybe responses may useful.","code":""},{"path":"vadrr-screener.html","id":"screening-form","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.4 Screening Form","text":"VADRR Abstract Screening also option include screening form (basically mini “survey” sorts) can aid screeners making decisions. may especially useful number screening criteria screeners need take account (want ensure give criterion full consideration). screening form can also used confirm right decision made.example, following project, screening form always required, screeners expected complete can render decision. Notice questions dropdown help screeners easily capture information.word caution regarding use screener form: using screener form can ensure thorough screen title/abstract, forcing screeners answer questions can slow screening process. , recommend use screening form, minimize number questions overly burden screeners.One possible benefit using screener form data Abstract Screener captured excel available download (see ). carrying scoping review, screener questions can used data analysis.","code":""},{"path":"vadrr-screener.html","id":"screening-form-builder","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.4.1 Screening Form Builder","text":"Let’s say decide create screening form. ?First, navigate Screening Form option Edit Forms pulldown upper navigation bar.open blank form builder. Click Add Question get started.can begin build questions. Note option select multiple response styles (e.g., radio button, checkbox, etc.).different question structure options may useful :Text: free text entry. recommend using seriously slow screening process.Numeric: number can entered. Unlikely useful screening.Checkbox: Select multiple options. can useful short list inclusion criteria, want screeners include criterion met. use option, may able get single screening form question.Dropdown: Select one option use pulldown menu select. Except yes/questions, less useful radio option.Radio: Select one option presents options user can see .Select One: Select one option provides ability user enter another write another option. unlikely generally useful screening, useful screening scoping review.Select Multiple: Select number pre-specified options additional ability write . unlikely generally useful screening. However, useful screeners confirm set outcomes reported want allow add additional outcomes., caution using screener form without thoughtful planning can slow screening process. use , keep simple (e.g., one checkbox question list inclusion criteria).","code":""},{"path":"vadrr-screener.html","id":"additional-options","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.5 Additional Options","text":"final set options following:Exclusive Users: limit screening tasks specified members team. large team (worried someone designated screener might hop tool begin screening), may want use option. click pulldown opens allows select team members designated screeners. Just select team members.Hide Author Information: projects, may want blind screeners citation authors. may case knowing author’s identity bias screeners either include exclude.Hide Journal Information: may want blind screeners journal article published believe knowing journal bias screeners include exclude.","code":""},{"path":"vadrr-screener.html","id":"finalizing-and-editing-your-screening-settings","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.6 Finalizing and Editing Your Screening Settings","text":"","code":""},{"path":"vadrr-screener.html","id":"configuring-reasons-and-tags","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.7 Configuring Reasons and Tags","text":"can use default settings change toggling button left setting.Allow users add reasons screening. Screeners allowed add additional reasons see fit. reasons appear screening tool team members’ tools. , want limit reasons exclusion (maintain consistency screeners) want toggle option .Allow users add tags screening. Similarly, allow users add tags. user-defined Reasons, screener defined new tag see option screening tool. may useful want allow screeners provide information title/abstract. However, given screeners can use Notes section, may want toggle one , leave , advise screeners use sparingly.Limit users one reason. Screeners need one reason exclude (e.g., wrong population). , often many reasons article may appropriate (wrong population, wrong intervention, wrong outcome, etc.). stage (abstract screening) less important screeners indicate reasons exclusion long identify one valid reason exclusion. can direct screeners just select one reason. However, want allow screeners select multiple reasons, toggle option .","code":""},{"path":"vadrr-screener.html","id":"setting-up-reasons","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.7.1 Setting Up Reasons","text":"can add reasons exclusion, recommend reasons correspond aspects PICO question(s) study design. VADRR comes set pre-specified reasons exclusion based PICO components recommend using (least start ). can add default Reasons clicking Add Default Reasons button. , standard set exclusion Reasons appear:can modify standard reasons following ways:Change position Reasons changing numbering Position column.Edit text Reason clicking edit button Edit columnDelete Reason clicking red trashcan icon Delete columnAdd additional reasons clicking small plus sign button bottom right corner list.might want alter reasons? Every project unique, may unusual reasons exclusion (e.g., animal study) additional reasons (Wrong Language). , recommend starting default reasons editing fit project.","code":""},{"path":"vadrr-screener.html","id":"adding-tags","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.3.7.2 Adding Tags","text":"choose use tags project, ’ll need enter manually—default set tags. Simply click plus sign button right tags space create tags.click plus sign button, new popup open. Simply enter text new tag click Create Tag button.noted Tags needed projects (especially simple projects), including Background Article option Tag generally good idea. allow screeners alert articles may useful providing background information related research.","code":""},{"path":"vadrr-screener.html","id":"terms-and-phrases-how-to-use-them-with-a-team","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.4 Terms and Phrases: How to Use Them with a Team","text":"VADRR Abstract Screener allows terms highlighted different colors indicate likely acceptance rejection. instance, following example, terms “asthma”, “COPD” “probiotics” strong indicators likely acceptance (highlighted green). terms “microbiome” “inflammatory cytokines” weak indicators acceptance.can also use different highlights indicate weak strong “likely reject.”Using colors terms phrases helps speed screening. instance, even screener reads entire abstract, abstract many terms flagged acceptance give strong initial indication article likely accepted. Similarly, highlighted colors rejection can help quickly flag article unlikely included.","code":""},{"path":"vadrr-screener.html","id":"setting-up-terms-and-phrases-for-groups-for-the-project","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.4.1 Setting Up Terms and Phrases for Groups for the Project","text":"individual screeners can highlight terms, best list terms phrases shared across screeners. promotes consistency!begin screening, meeting screening team discuss inclusion exclusion criteria, good idea brainstorm team terms believe likely indicate inclusion exclusion. instance, limiting studies adults, terms like “child,” “children,” “infants,” etc. may terms want highlight likely exclusion.first open screening window, can scroll right panel Terms Phrases section. see following:point, options:\n* Add Default Groups clicking Add Default Groups button. create list four groups (Group 1, Group 2, etc.) colors pre-assigned. can change group names double clicking group name, changing label, clicking check mark accept changes.can change color clicking color bar. may important members team red/green color blind.can click Edit Terms manually add list terms indicative strongly weakly accept reject. team identified terms categories, want set ahead time. , can use Download Groups button create JSON file contains information. Send file screeners instructions use Import Groups button pull highlighting codes. promote team consistency.Finally, can completely delete group clicking trashcan right group.Manually create groups. decide alter default groups, can create using Add new group field just Download Groups button., simply enter new group name hit return. new group now show list default color. Change color desired.Create Groups assign terms colors directly JSON file. familiar JSON files, can use JSON editor create code uploading JSON file. example JSON file syntax define groups, assign colors, indicate terms associated group. can also download JSON file edit manually, re-upload .","code":""},{"path":"vadrr-screener.html","id":"resolving-conflicts","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.5 Resolving Conflicts","text":"screening proceeded, inevitably screeners disagree whether include exclude article. Additionally, article marked “maybe” marked “conflict”. need resolve conflicts.can find Resolve Conflicts button main Abstract Screening page.Clicking button open Screener page. point, couple options:Resolve conflict referring screener decisions rationales. abstract, now see labels assigned screeners, along whatever reasons notes screeners entered. can read abstract decide screener decisions (make entirely different decision ). Use green red decision button make final inclusion judgment. Resolve conflict referring screener decisions rationales. abstract, now see labels assigned screeners, along whatever reasons notes screeners entered. can read abstract decide screener decisions (make entirely different decision ). Use green red decision button make final inclusion judgment. Resolve conflict blinded. want make truly blind decision, can click purple Labels button eye just screener decisions. make screener decisions disappear can make assessment . Note decision overrides screener decisions.Resolve conflict blinded. want make truly blind decision, can click purple Labels button eye just screener decisions. make screener decisions disappear can make assessment . Note decision overrides screener decisions.","code":""},{"path":"vadrr-screener.html","id":"understanding-and-using-the-machine-learning-results","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.6 Understanding and Using the Machine Learning Results","text":"VADRR incorporates powerful Machine Learning (ML) tool (previously Abstrakr) facilitate screening tasks. work?Pearls (articles pre-identified meet inclusion criteria) marked inclusion manually via Project Dashboard. provides first bit information ML model.Screeners initially screen 100 titles abstracts. (second bit information ML needs). first round, articles presented screeners random order.ML creates predictive model (overnight) rearranges articles articles highest probability screened moved front screener queue.Depending complexity project, ML able get pretty reliable model inclusion/exclusion criteria within couple training rounds.Screening continues stopping criteria reached (assumption ML “screened” rest articles.Note: system set err side sensitivity. instance, ML model predicts article 4% chance inclusion, number multiplied 10 appears article 40% probability included. design system runs low chance missing key articles.","code":""},{"path":"vadrr-screener.html","id":"when-do-you-see-results","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.6.1 When Do You See Results?","text":"system set run ML model 100 completed screenings automatically. means need 100 double-screened articles agreement screeners. Note, Maybe responses count.way force ML run fewer screeners (though typically recommend since without sufficient number accurately identified accept/reject decisions, model unlikely able produce reliable model.force ML run fewer 100 new screens, toggle Force Training button main Abstract Screening screen.","code":""},{"path":"vadrr-screener.html","id":"what-do-the-results-mean","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.6.2 What Do the Results Mean?","text":"ML engine runs behind scenes, need worry . can get results model, can useful understanding much screening left .main Abstract Screening page, just Force Training button, Machine Learning Results. Clicking button take page can see ML results. lot resources page, break .Total Number Citations: many citations team successfully screened.Latest Model Time: last time date ML model generatedRejection Streak Counter: number articles rejected two screeners.Estimated Coverage: graphical presentation many studies screened (x-axis) many articles left estimated included. gives rough sense many articles team left screen.Percentage unscreened: proportion articles left screened (example, 46.3% articles unscreened).Untrained citations: number articles double-screened, machine yet processed . ML generate new model counter gets 100.Highest Score: probability highest-scoring article. Higher probabilities indicate likely inclusion. example, highest-scoring article 99.88% probability included.Score Distribution: histogram shows many articles fall different deciles probability distribution. case, see nearly 500 articles 0% 10% probability included (thus, screeners likely never see articles). see much smaller numbers articles 80%-90% range 90-100% range.Enter threshold: want see many articles certain probability included, can change value. default 50%. let’s say set stopping rule articles 40%. can change value .4 get sense many articles left screen. example, can see n=146 articles greater 50% chance inclusion.Next, see table Top 20 Unscreened Citations. valuable table shows reference information articles highest probability included. useful confirming articles left screen likely included. hit stopping criteria (see ), can check titles table confirm none likely included.Note rather wait article double-screened, can click Label link right citation manually accept reject. important remember can break protocol (since article double-screened). , judicious changing label article table.bottom Machine Learning Results page blue button looks like :button allows open series model diagnostic measures. Clicking button show following:right, see confusion matrix shows well model performing. instance, left half matrix shows status articles ML predicted included. n=175 articles ML predicted accepted, n=62 accepted n=113 . Remember, ML set sensitive, likely predict article accepted even isn’t want miss potential articles. Notice 58 articles ML predicted rejected, n=2 rejected. , want number low possible.table right provides formal metrics model’s performance.Precision: measure often model correctly predicts including article (typically fairly low given system set sensitive)Sensitivity: True Positive rate (also called “recall”), tells proportion actually included articles correctly identified included model. want number high (example, 97%).F1 Score: harmonic mean precision sensitivity. overall measure model’s accuracy. , VADRR set overly sensitive, shouldn’t anticipate high value score.Accuracy: measure overall correctness model. proportion correctly predicted articles total number articles.probably sense , way model set (.e., sensitive), numbers going particularly useful. measures, want check Sensitivity. give sense likelihood potentially useful article missed.","code":""},{"path":"vadrr-screener.html","id":"when-should-we-stop-screening","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.6.3 When Should We Stop Screening?","text":"area debate evidence synthesis community. really need screen citations (let’s say thousands) ML working ? , remaining citations low probability inclusion, really make sense continue screening ?recently, researchers developing stopping rules (.e., humans stop screening, rest citations assumed screened ML model). standard screening stop. common approaches include:ML trained, 100 articles row rejected, stop screening.none remaining articles greater 40% chance inclusion (really means 4% chance inclusion).criteria combined.Whichever choose (can choose different stopping rules mentioned ), sure document plan protocol report.","code":""},{"path":"vadrr-screener.html","id":"downloading-screening-results","chapter":"4 Screening: Insructions for Screening Set Up (Project Leads)","heading":"4.1.7 Downloading Screening Results","text":"Results screening tasks (Abstract Full-text screening), can downloaded. See VADRR 7. Getting Results VADRR","code":""},{"path":"screening-instructions-for-screeners.html","id":"screening-instructions-for-screeners","chapter":"5 Screening: Instructions for Screeners","heading":"5 Screening: Instructions for Screeners","text":"page meant provide instructions project members using VADRR Abstract Screener tool (previously Abstrakr).","code":""},{"path":"screening-instructions-for-screeners.html","id":"the-basics","chapter":"5 Screening: Instructions for Screeners","heading":"5.1 The Basics","text":"","code":""},{"path":"screening-instructions-for-screeners.html","id":"getting-started","chapter":"5 Screening: Instructions for Screeners","heading":"5.1.1 Getting Started","text":"get abstract screening tool Projects page (landing page VADRR log ), simply click Screening pulldown project working :click Abstract Screening tool, see one “screening tasks”. instance, image can see three different tasks:pilot screening task (small set citations team used calibrate screening decisions,pilot screening task (small set citations team used calibrate screening decisions,n-size-single screening task (one screener set screen n=100 citations),n-size-single screening task (one screener set screen n=100 citations),double-perpetual screening task (citation screened two people, limit number citations).double-perpetual screening task (citation screened two people, limit number citations).Note: screener, see one type screening task sure use, contact project lead confirm working .Simply click Continue Screening button begin (continue) screening.","code":""},{"path":"screening-instructions-for-screeners.html","id":"the-screening-page","chapter":"5 Screening: Instructions for Screeners","heading":"5.2 The Screening Page","text":"use window cycle title/abstracts citations assigned .Note: need change windows different citations. click decision buttons (green check, red X purple ?), system automatically move next citation queue!walk part screen.","code":""},{"path":"screening-instructions-for-screeners.html","id":"title-abstract-and-publication-information","chapter":"5 Screening: Instructions for Screeners","heading":"5.2.1 Title, Abstract and Publication Information","text":"left side screen, see title, abstract publication information (project leader author journal hidden). review information make determination regarding inclusion exclusion (maybe decide).","code":""},{"path":"screening-instructions-for-screeners.html","id":"include-exclude-maybe-choices","chapter":"5 Screening: Instructions for Screeners","heading":"5.2.2 Include / Exclude / Maybe Choices","text":"bottom right screen three buttons:Green check mark: click button mark article included project. article must meet inclusion criteria included.Purple question mark: click button unsure whether article meets inclusion criteria.Red X mark: click button believe article meet inclusion criteria rejected.Tips using Maybe: may tempting use Maybe button often simply sure, given information title abstract, whether article screened . However, caution using Maybe recommend using infrequently possible. several reasons .Using Maybe automatically sets article “conflict” status. Conflict status two screeners disagree (, case, single screener make decision). , means decision still made, consolidator. best , screener, make decision provide much rationale necessary decision hesitations (e.g., Notes).Err side inclusion. title/abstract screening just first screening step—followed full-text screening step—even article ultimately rejected, best let rejected information available (full-text screen).recommend using Maybe genuine question inclusion/exclusion criteria. confusion brought project leader clarification.","code":""},{"path":"screening-instructions-for-screeners.html","id":"rejection-reasons","chapter":"5 Screening: Instructions for Screeners","heading":"5.3 Rejection Reasons","text":"citation can marked rejection, Rejection Reason must provided. project lead set list reasons select . Check project lead questions reasons mean. project lead may allow add additional reasons (check project lead). , can add additional reasons clicking plus sign bottom right Rejection Reasons list.Note: reasons project may differ provided example . Also, project lead may allow select one reason reject article (check project lead). allowed choose one reason (e.g., wrong population, wrong intervention, wrong outcome, etc.), select one .","code":""},{"path":"screening-instructions-for-screeners.html","id":"using-tags","chapter":"5 Screening: Instructions for Screeners","heading":"5.4 Using Tags","text":"projects use tags. list often always used allow provide bit information article. Often, see option “Background article.” Sometimes, may run across article meet inclusion criteria (e.g., review article commentary) think may nonetheless useful project. Selecting Background article tag (available) allow flag article pulled project.","code":""},{"path":"screening-instructions-for-screeners.html","id":"using-notes-1","chapter":"5 Screening: Instructions for Screeners","heading":"5.5 Using Notes","text":"Notes free text field can use reason. Typical reasons using Notes:think article included excluded, may lingering doubt. can use notes field jot thoughts. used case conflict whether include exclude article.gave maybe response. Depending project may required enter rationale Notes field select Maybe option (purple button bottom). enter information weren’t sure one way another—perhaps little information provided abstract.Notes can used reason . may want simply put rationale making decision made. typically necessary (except Maybe projects) option.","code":""},{"path":"screening-instructions-for-screeners.html","id":"screening-form-1","chapter":"5 Screening: Instructions for Screeners","heading":"5.6 Screening Form","text":"projects may use short screening form help assessment. Since may sometimes difficult remember inclusion criteria (many project), project lead may provide question series questions regarding whether inclusion criteria met. simply way help screening.example checklist inclusion criteria must met article included. Note completed screening form question, must mark screening form complete register response.questions regarding screening form, consult project lead directions.","code":""},{"path":"screening-instructions-for-screeners.html","id":"highlighting-terms-for-inclusion-and-exclusion","chapter":"5 Screening: Instructions for Screeners","heading":"5.7 Highlighting Terms for Inclusion and Exclusion","text":"additional feature screening tool terms phrases indicating likely inclusion exclusion can highlighted aid screening process. Highlighting certain terms can speed screening. following example, term “cognitive bias” strongly indicates likely acceptance, “inference” weakly indicates acceptance. contrast, terms “drug” “drugs” strongly indicate rejection.first open abstract much highlighted colors indicating “likely accept”, ’ll know (even reading full abstract) article may good candidate inclusion. Alternatively, many terms indicate “likely reject” can suspect article likely rejected upon full reading.two ways Terms Phrases can highlighted:Project-wide terms phrases: terms phrases decided upon team indicate likely inclusion exclusion. project lead generally create list (working members team) share file (json file). directed import file screening project. , terms take appropriate highlight. import file provided project lead, use Import Groups (JSON format) button Terms Phrases box.Just follow instructions import project list terms phrases.Individualized terms phrases: can also highlight terms . couple ways , easiest simply highlight term phrase within abstract title assign value. highlight word set words, popup open. Simply select appropriate valence highlighted text.Note can also download Terms Phrases Groups defined (e.g., share rest team).Good Practice Note: make sure everyone page screening, good idea entire team working list terms phrases. Work project lead team members identify terms work share across screeners. ","code":""},{"path":"screening-instructions-for-screeners.html","id":"reviewing-and-re-screening","chapter":"5 Screening: Instructions for Screeners","heading":"5.8 Reviewing and Re-screening","text":"notice three buttons center screen just left abstract text.buttons allow following:Labels: want review screenings already completed want return previously screened abstract rescreen (perhaps changed mind), can click button. , popout open left list articles ’ve already screened. clicking title article, can rescreen .Continue Screening: used “Labels” button jump another screened citation, can use Continue Screening button jump back last abstract queue.Exit: want end screening session closeout. Simply click button.","code":""},{"path":"template.html","id":"template","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6 Tips for Creating a Data Extraction Template","text":"talk build different sections let’s talk first general good practices building extraction template.","code":""},{"path":"template.html","id":"structure-your-template-based-on-your-analytic-framework","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.0.1 Structure Your Template Based on Your Analytic Framework","text":"First, types information (data) ’ll want pull research articles guided PICO question analytic framework. Take look back PICO analytic framework think carefully pieces information ’ll need answer question. instance, looking example analytic framework, can already see number fields need add extraction template:\nadditional ideas field extract project, see Chapter 5 Cochrane Handbook.","code":""},{"path":"template.html","id":"organize-questions-within-tabs","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.0.2 Organize Questions within Tabs","text":"Second, know organize questions within template. Happily, VADRR makes easier organizing different types information ’ll need series tabs. example structured data entry form Design Details tab.\n","code":""},{"path":"template.html","id":"goldilocks-principle-for-data-collection","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.0.3 Goldilocks Principle for Data Collection","text":"Third, remember balance little information much information. principle data extraction systematic scoping reviews extracting information need format can use. don’t want extract everything (otherwise, just work full text articles), want enough information allow planned analyses.little information extracted mean either limited analysis may mean going back later update template capture information missed.much information, find yoursel wasting time extracting information need analysis.instance, important plan ahead time sub-analyses carrying meta-analysis. , ’ll need extract information differences samples, interventions, measurement methods, etc. used different research articles. Taking study characteristics account can provide strong evidence interventions exposures tests work differently (.e., different outcomes) different situations. plan ahead capturing information (without trying extract every piece information study).","code":""},{"path":"template.html","id":"use-dependencies-to-help-your-extractors","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.0.4 Use Dependencies to Help Your Extractors","text":"Fourth, can use Dependencies functionality help guide data extractors () knowing questions answer, can safely ignore.set appropriate dependencies, click Save Exit button top right dependency tool screen.","code":""},{"path":"template.html","id":"getting-started-with-the-extraction-template-builder","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.0.5 Getting Started with the Extraction Template Builder","text":"\nList Available Tabs: left see list default tabs defined VADRR.\n\nAdd Section Button: list button: Add Section. projects require additional tabs, flexibility add additional tabs.\n\nSave Instructions: general instructions extractors particular tab, can enter instructions text box.\n\nTab Dependencies: two key tabs structure tabs: Arms Outcomes. make Arm Details dependent Arms, question Arm Details repeat arm defined Arms tab. Similarly, Outcome Details tab dependent Outcomes tab, question Outcome Details tab repeat every outcome defined Outcomes tab. Finally, going carry risk bias outcome (rather article whole), want make Risk Bias tab dependent Outcomes.\n\nPreview Section: can use button top preview look questions.\n\nAdd Question: button allows add new question.\n","code":""},{"path":"template.html","id":"whats-next","chapter":"6 Tips for Creating a Data Extraction Template","heading":"What’s Next?","text":"next series pages show actually set different types questions VADRR.","code":""},{"path":"template.html","id":"struc-ques","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.1 General Principles for Structuring Questions","text":"cover several topics structuring creating questions.","code":""},{"path":"template.html","id":"how-to-structure-questions","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.1.1 How to Structure Questions","text":"decided information need extract, need think best way organize format question capture information optimal format analysis. First, general principle:\ngeneral, possible, best use structured rather free text questions.\n\nText Field: option useful free text entry type information article highly variable unstructured. instance, may want pull narrative article blinding carried (since many ways blind study). , instance, simple text box used capture information presented following example.\n\nHowever, let’s say planned sub-analysis determine whether type blinding effect outcomes. case, may want information text format, want create structured question allow us add type blinding subgroup meta-analysis. case, use following (used Checkbox structure text option “”):\n\nNumeric Field: free-text entry field can used enter numerical values (alphanumeric entry allowed).\n\nCheckbox (select multiple): option good multiple characteristics may present study (different types blinding example).\n\nDropdown: option similar Radio Button option () useful one alternative possible list options fairly restricted (e.g., Yes/). look like data entry screen.\n\nRadio button (select one): Like Dropdown, option useful one alternative possible, unlike Dropdown useful several possible options (awkward Dropdown). radio button option look like .\n\nSelect One (write-option):Select One (write-option)**: want offer extractors use Dropdown flexibility also typing another option, can use question format. However, want use format write-information anything couple words. want space allow extractors enter detail different option necessary. Use radio button question “” option place free-text question second column (’ll show set one column row question later).\n, now second column provides structure options first column. can leave free text adjust default number characters allowed.\nSelect Multiple (write-option): question format allows data extractor select one option (like Checkbox type question) well write option listed. Select One (write-option), use format want allow exactors enter text detailed word two.\n","code":""},{"path":"template.html","id":"setting-up-the-questions","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.1.2 Setting Up the Questions","text":"Now sense different types questions available, actually set question? use example setting radio button question.First, click Add Question button. new empty question appear bottom builder screen.Second, add question text (e.g., Select appropriate study design).Third, add instructions help extractors.Fourth, select appropriate question structure. select Radio. (Note, select question structure question automatically save page refresh. Scroll bottom find question .)Fifth, enter first option center field:Sixth, enter additional options lower entry field. Write option hit Enter save new option (, question save, page refresh). Continue entering answer options question complete. point, can reorder, edit delete options entered.","code":""},{"path":"template.html","id":"using-multiple-rows","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.1.3 Using Multiple Rows","text":"benefit complicated question structure? Rather create whole series separate questions (make page quite long), can use complex question structures gather required information less space.","code":""},{"path":"template.html","id":"reordering-duplicating-and-removing-questions","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.1.4 Reordering, Duplicating and Removing Questions","text":"\ncan reorder questions point.\n\ncan duplicate questions.\n\ncan delete question\n","code":""},{"path":"template.html","id":"question-structure-faqs","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.1.5 Question Structure FAQs","text":"\nable create good Radio Button Checkbox options assumes already knowledge common appropriate options begin structure question. means full-text review stage article selection, looking common patterns options across articles. , instance, answering diagnostic accuracy question three () common types test device manufacturers, take note create structured question allows extractor choose among . Allowing free-text entry situation mean go back analysis phase reclassify device manufacturer entries discrete categories. Save time end structuring questions front possible.\n\nVADRR allows great flexibility structuring questions appear. Sometimes, may want whole series separate questions, multiple sub-questions “fit” within single question. instance, following question seeks collect detail different aspects intervention, requires additional detail intervention component used.\nmultiple row multiple column format used structure question.just created question went preview , don’t see new question. wrong?\nquestions automatically “inherit” key questions defined beginning project. add key questions later, select key questions question apply. example , question sleep apnea added later project. questions automatically appear key question article addresses sleep apnea.implication selecting Key Questions question applies can customize extraction template, making questions appear key questions questions appear key questions.Bottom line: data entry questions linked Key Questions, Key Question selected data entry question, see data entry question show data entry screen.","code":""},{"path":"template.html","id":"piloting-your-questions-for-extractions","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.1.6 Piloting Your Questions for Extractions","text":"Finally, important thing keep mind almost certainly create perfect data extraction template first try. Sometimes ’ll realize questions (options within questions) included didn’t. Sometimes ’ll find data extractors find structure question confusing., data extraction templates pilot tested different team members. can assigning couple articles extraction obtaining feedback team members. extracting alone, plan extract data two three research studies (making alterations extraction template), final extraction form.","code":""},{"path":"template.html","id":"arm-suggest","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.2 Setting up Arm or Diagnostic Test Suggestions","text":"two tabs within VADRR special ways setting questions: Arms (Diagnostic Tests) Outcomes (Diagnoses). tabs different names depending whether carrying diagnostic accuracy project (case talking Diagnostic Tests Diagnoses) type project (case talking Arms Outcomes)., ’ll show set arms provide tips useful ways .","code":""},{"path":"template.html","id":"difference-between-arms-and-diagnostic-tests","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.2.1 Difference Between Arms and Diagnostic Tests","text":"First, Arm setup page projects answering Diagnostic Accuracy questions.\npage projects set answer Diagnostic Accuracy questions. ’ll notice couple tabs different.’ll notice Arms (Diagnostic Tests) setting template providing extractor suggestions. Think building menu extractors can quickly easily draw specifying arms research study.field need enter Name field (best enter description descriptions best left extractor peculiarities particular article).","code":""},{"path":"template.html","id":"how-to-name-arms","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.2.2 How to Name Arms","text":"One thing realize front authors different articles may name essentially arms differently. instance, let’s say PICO question : Among people mental illness, effectiveness multi-component weight loss program compared usual care managing weight status? two studies name essentially arms different ways:Smith 2018: Treatment arm name, “Lifestyle Intervention”; Comparison arm name, “Usual care”Jones 2019: Treatment arm name, “Active Life Intervention”; Comparison arm name, “Standard care”obvious problem extractors name arms exactly authors , go carry analysis sort different names figure intervention interest (“” PICO) comparator arms (“C” PICO). extractors provided structure training front, can mean huge amount work cleaning arm names analysis phase project.interested specific commonly labeled surgery, treatment, drug, etc., , comparator condition always placebo, can provide suggest descriptive “innovative treatment” “comparison treatment”. case, setting arms simple.Now, word caution: using multiple generic labels innovative () “improvement” practice intervention, double extracting data articles (.e., two data extractors working separately article), can cause confusion Consolidation phase project (, third person reconciles differences extractors). Extractor 1 might label arm “Innovative Practice 1” extractor labels arm “Improvement Practice 2”. case, recommend extractors use short description differentiate two innovation arms (, less frequently, two comparison arms).may also want extractors communicate ahead time arm labeled Practice 1 Practice 2. feasible, may want come descriptive (rather generic) label multi-arm studies. , training extractors ahead time key!may wondering capture detail arms assign generic labels. ’ll cover next section.","code":""},{"path":"template.html","id":"when-things-get-much-more-complicated-clinical-practice-guidelines","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.2.3 When Things Get Much More Complicated: Clinical Practice Guidelines","text":"single question systematic reviews, approach generally fine. , projects encompass many questions (like creating Clinical Practice Guidelines)? case, may need several arm suggestions. Always try plan make easier data extractors (less frustration, less time, fewer mistakes). example:just every question clinical practice guideline separate project within VADRR? certainly option may best projects. However, article may apply several clinical practice questions, may efficient keep within project avoid unnecessary duplicate (triplicate!) extractions.Remember, can use multiple key questions can assign different questions (data entry fields) key questions. takes little planning organization may actually help end.","code":""},{"path":"template.html","id":"how-to-set-up-and-name-diagnostic-tests","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.2.4 How to Set Up and Name Diagnostic Tests","text":"Diagnostic Accuracy systematic review, little prep work need can set Diagnostic Tests (Diagnoses).first tell VADRR Results going proper format (different types systematic reviews). , go Results tab first time, see following:naming Diagnostic Tests, basic principles apply mentioned naming Arms: keep simple.instance, familiar polymerase chain reaction (PCR) tests, know different types. Rather extractors enter lots detail tests (, heaven forbid, give essentially test different names) Diagnostic Tests page, keep test suggestions simple (e.g., tests common type, like PCR blood culture) capture detail tests Diagnostic Test Details page.","code":""},{"path":"template.html","id":"arms-details","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.3 The Importance of Arms or Diagnostic Test Details","text":"Treatments, interventions tests rarely exactly studies. example:\nDrug studies: dosage, timing, length treatment may vary somewhat studies.\n\nInterventions: general surgery may differ somewhat technique studies. interventions may include multiple components may combine components different ways across different studies.\n\nDiagnostic accuracy studies: test manufacturers, analytic pre-analytic procedures may vary studies.\nthinking ahead talking using generic suggestions arms, may wondered, “can capture details differences arms?”Arm (Diagnostic Test) Detail tab comes . Capturing details differences arms going vital analysis phase capturing information may explain substantial amount heterogeneity meta-analysis. Essentially, want use Arm Details tab merely capture details different arms, want capture differences among studies treatments, interventions, tests exposures carried measured.differences can used later define subgroup analyses (serve covariates meta-regression) meta-analyses later project!protocol (assuming protocol), likely defined number characteristics might serve effect modifiers. capture detail characteristics Arms Details Test Details tab.bears repeating: capturing detail may prove huge benefit analysis phase.","code":""},{"path":"template.html","id":"what-details-should-you-capture-in-the-arms-or-diagnostic-test-details-tab","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.3.1 What Details Should You Capture in the Arms or Diagnostic Test Details Tab?","text":"depends heavily purpose questions (, noted , defined protocol). also assumes understanding differences might actually make difference results different studies., offer suggestions types Arm Detail questions based different types systematic review questions.Dosage (much? long? often?)TechniqueProvider (e.g., physician, physical therapist, nurse, dietitian, etc.)Mode treatment (e.g., counseling: face face? person?)Intervention format (e.g., individual sessions, group sessions, mixed?)multi-component interventions, different components (e.g., drug, dietary, physical activity, counseling, etc.)?Techniques providing intervention (e.g., physical activity: walking versus aerobic exercise versus strength training, etc.)intervention chains (.e., sequenced practices), components intervention chain included (e.g., pre-analytic procedures –> organism identification –> organism susceptibility –> stewardship communication treating clinician –> treatment technique)?Dosage (much? long? often?)Provider (e.g., physician, physical therapist, nurse, dietitian, etc.)Mode treatment (e.g., counseling: face face? person?)Intervention format (e.g., individual sessions, group sessions, mixed?)Test manufacturerPre-analytic procedures (e.g., diagnosis C diff, requirement unformed stools prior test request?)Differences analytic techniqueDifferent methods measuring exposure (e.g., different methods assessing dietary intake methods airborne hazard measurement)potential confounding variables (.e., sources exposure factors mitigate modify result)list exhaustive, need every one suggested questions asked different types projects. key, however, plan ahead begin building data extraction template details likely important (say, may perhaps affect differences results subjects studies).couple suggestions:\nworking part team knowledge topical area: plan team discussion identify Arm Details questions extracted.\n\nworking alone deep understanding topical area: full-text review phase study selection, keep notes differences see among studies characteristics listed . Reading re-reading articles may help find patterns ’ll want capture data extraction phase.\nOne last thing: suggestions mentioned earlier resource creating structured (versus free text) questions particularly important Arms Details. Using structured questions Arm Details allow easily sort filter studies commonalities differences. make much easier identify factors covariates subgroup meta-analyses.","code":""},{"path":"template.html","id":"outcome-suggest","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.4 Setting up Outcome or Diagnoses Suggestions","text":"Setting suggestions Outcomes (Diagnoses, Diagnostic Accuracy project) similar setting Arms, though things think .first principle setting Outcomes Diagnoses tab suggest outcomes interest. Authors generally report many different outcomes, may interest project. Eager extractors people new carrying systematic reviews may mistakenly think need extract every outcome reported study. , set suggestions ahead time, can focus avoid wasted time.","code":""},{"path":"template.html","id":"setting-up-outcomes","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.4.1 Setting Up Outcomes","text":"Suggest Domain: outcome measurement interest. instance, PICO question “Among children adolescents, effectiveness multi-component weight management program, compared single-component interventions, bringing improvements weight status?”, want enter “weight status” suggestion number different ways measuring weight status: BMI (body mass index), percent weight change, weight change, percent body fat, etc. , use specific types measurements Domains rather general outcomes (like weight status).\nContinuous variables numeric variables infinite number values two values. example, BMI can take numeric value (e.g., 25.2, 25.3, 25.4)\n\nCategorical variables contain finite number categories distinct groups. example, US Centers Disease Control BMI Categories (underweight, normal weight, overweight, obese).\nalso discrete (counting) variables (e.g., numeric variables countable number values two values–like number hospital visits year), VADRR typically treat discrete variables continuous.click Suggest Type Domain dropdown, ’ll see options.\nBMI (continuous) outcome, SRDR+ automatically set data input structure Results tab “expect” mean, standard deviation number analyzed.\n\nBMI Category (categorical) outcome, SRDR+ automatically set data input structure Results tab “expect” number “events” number analyzed.\nSuggest Specific Measurements Suggest Timepoints fields? useful project focusing specifically certain measurements (e.g., extracting visual analog scale measures pain excluding types pain measurements), project interested specific timepoints (e.g., Baseline one-year outcomes ignoring timepoints). found best let data extractors capture specific measures timepoints reported authors selected studies focus differentiating specific measures timepoints analysis phase.","code":""},{"path":"template.html","id":"setting-up-diagnoses","chapter":"6 Tips for Creating a Data Extraction Template","heading":"6.4.2 Setting up Diagnoses","text":"case missed section setting Diagnostic Accuracy template, see section 5.2.2 resource. Hint: don’t see Diagnoses tab (, rather, see Outcome tab), means set project right. Pop back earlier section see set template Diagnostic Accuracy project.–>\n–>\n","code":""}]
